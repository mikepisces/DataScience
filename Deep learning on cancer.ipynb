{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv(r\"C:\\Users\\Khushi\\Desktop\\BreastCancer.csv\")\n",
    "cancer.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Id  Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  \\\n",
       "0           1  1000025             5          1           1              1   \n",
       "1           2  1002945             5          4           4              5   \n",
       "2           3  1015425             3          1           1              1   \n",
       "3           4  1016277             6          8           8              1   \n",
       "4           5  1017023             4          1           1              3   \n",
       "\n",
       "   Epith.c.size  Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses   Class  \n",
       "0             2          1.0            3                1        1  benign  \n",
       "1             7         10.0            3                2        1  benign  \n",
       "2             2          2.0            3                1        1  benign  \n",
       "3             3          4.0            3                7        1  benign  \n",
       "4             2          1.0            3                1        1  benign  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.Class.replace({\"benign\" : 0 , \"malignant\":1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Id  Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  \\\n",
       "0           1  1000025             5          1           1              1   \n",
       "1           2  1002945             5          4           4              5   \n",
       "2           3  1015425             3          1           1              1   \n",
       "3           4  1016277             6          8           8              1   \n",
       "4           5  1017023             4          1           1              3   \n",
       "\n",
       "   Epith.c.size  Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0             2          1.0            3                1        1      0  \n",
       "1             7         10.0            3                2        1      0  \n",
       "2             2          2.0            3                1        1      0  \n",
       "3             3          4.0            3                7        1      0  \n",
       "4             2          1.0            3                1        1      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_x = cancer.iloc[:, [2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  Epith.c.size  \\\n",
       "0             5          1           1              1             2   \n",
       "1             5          4           4              5             7   \n",
       "2             3          1           1              1             2   \n",
       "3             6          8           8              1             3   \n",
       "4             4          1           1              3             2   \n",
       "\n",
       "   Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses  \n",
       "0          1.0            3                1        1  \n",
       "1         10.0            3                2        1  \n",
       "2          2.0            3                1        1  \n",
       "3          4.0            3                7        1  \n",
       "4          1.0            3                1        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_y = cancer.iloc[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAMPLING\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_x_train, cancer_x_test,cancer_y_train, cancer_y_test = train_test_split(cancer_x, cancer_y, test_size= 0.2 , random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the data becomes unitless, so we scale\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(cancer_x_train)\n",
    "scaler.fit(cancer_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cancer_x_train = scaler.transform(cancer_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cancer_x_test = scaler.transform(cancer_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstandardize_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mweighted_masked_objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_num_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorboard_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Khushi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model =  tf.keras.models.Sequential()\n",
    "model.add =(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add =(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add =(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add =(tf.keras.layers.Dense(2 , activation = tf.nn.softmax))  ## no. of layers in your target variable\n",
    "## softmax is used when there are more than 2 layers in your target variable\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy', metric = ['accuracy'])\n",
    "\n",
    "## adam - stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cancer_x_train = np.array(scaled_cancer_x_train)\n",
    "scaled_cancer_x_test = np.array(scaled_cancer_x_test)\n",
    "cancer_y_train = np.array(cancer_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 436 samples, validate on 110 samples\n",
      "Epoch 1/20\n",
      "436/436 [==============================] - 0s 208us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 2/20\n",
      "436/436 [==============================] - 0s 94us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 3/20\n",
      "436/436 [==============================] - 0s 55us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 4/20\n",
      "436/436 [==============================] - 0s 69us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 5/20\n",
      "436/436 [==============================] - 0s 73us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 6/20\n",
      "436/436 [==============================] - 0s 87us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 7/20\n",
      "436/436 [==============================] - 0s 55us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 8/20\n",
      "436/436 [==============================] - 0s 69us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 9/20\n",
      "436/436 [==============================] - 0s 73us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 10/20\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 11/20\n",
      "436/436 [==============================] - 0s 71us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 12/20\n",
      "436/436 [==============================] - 0s 114us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 13/20\n",
      "436/436 [==============================] - 0s 71us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 14/20\n",
      "436/436 [==============================] - 0s 73us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 15/20\n",
      "436/436 [==============================] - 0s 69us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 16/20\n",
      "436/436 [==============================] - 0s 117us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 17/20\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 18/20\n",
      "436/436 [==============================] - 0s 69us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 19/20\n",
      "436/436 [==============================] - 0s 71us/sample - loss: 3.9055 - val_loss: 3.6184\n",
      "Epoch 20/20\n",
      "436/436 [==============================] - 0s 87us/sample - loss: 3.9055 - val_loss: 3.6184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10b16a05518>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_cancer_x_train, cancer_y_train, epochs= 20, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "input_1:0 is both fed and fetched.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-943460a068fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcancer_x_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \"\"\"\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3287\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m         session != self._session):\n\u001b[1;32m-> 3289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   3220\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3221\u001b[0m     \u001b[1;31m# Create callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3222\u001b[1;33m     \u001b[0mcallable_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3223\u001b[0m     \u001b[1;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3224\u001b[0m     \u001b[1;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \"\"\"\n\u001b[0;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1444\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[1;32m-> 1446\u001b[1;33m             session._session, options_ptr)\n\u001b[0m\u001b[0;32m   1447\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: input_1:0 is both fed and fetched."
     ]
    }
   ],
   "source": [
    "pred1 = model.predict_classes(cancer_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab= confusion_matrix(pred1, cancer_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[427,  71],\n",
       "       [  5, 164]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.6056971514243"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.diagonal().sum()/tab.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\",dimension =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Khushi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Users\\Khushi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\Users\\Khushi\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Khushi\\AppData\\Local\\Temp\\tmpkrhls0i7\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000010B0B622F28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Khushi\\\\AppData\\\\Local\\\\Temp\\\\tmpkrhls0i7'}\n"
     ]
    }
   ],
   "source": [
    "classifier = learn.DNNClassifier(feature_columns =  feature_columns, hidden_units= [10,20,10], n_classes= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_y_train= cancer_y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A7F400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A8CCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A8CCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A8CCF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16A8CCF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16BC26D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16BC26D8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16BC26D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B16BC26D8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Khushi\\AppData\\Local\\Temp\\tmpkrhls0i7\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Khushi\\AppData\\Local\\Temp\\tmpkrhls0i7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3505996, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 233.364\n",
      "INFO:tensorflow:loss = 0.17629659, step = 1101 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.83\n",
      "INFO:tensorflow:loss = 0.05915258, step = 1201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.879\n",
      "INFO:tensorflow:loss = 0.3081706, step = 1301 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.422\n",
      "INFO:tensorflow:loss = 0.03427746, step = 1401 (0.212 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1427 vs previous value: 1427. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into C:\\Users\\Khushi\\AppData\\Local\\Temp\\tmpkrhls0i7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.11971337.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x0000010B0B6229E8>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=1, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x0000010B01F4E048>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(scaled_cancer_x_train, cancer_y_train, steps = 500, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B0CE42320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B0CE42320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B0CE42320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B0CE42320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B148CDC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B148CDC88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B148CDC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B148CDC88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000010B105C0A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Khushi\\AppData\\Local\\Temp\\tmpkrhls0i7\\model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_new = classifier.predict_classes(scaled_cancer_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tab1 = confusion_matrix(list(pred_new), cancer_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.8102189781022"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab1.diagonal().sum()  / tab1.sum() *100   #### gives the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93,  1],\n",
       "       [ 2, 41]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LungCap with deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcn =pd.read_csv(r\"C:\\Users\\Khushi\\Desktop\\sep14\\LungCapData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcn.Smoke.replace({\"no\":0, \"yes\" :1},inplace =True)\n",
    "lcn.Gender.replace({\"male\":1, \"female\" :0},inplace =True)\n",
    "lcn.Caesarean.replace({\"no\":0, \"yes\" :1},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Caesarean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>62.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Height  Smoke  Gender  Caesarean\n",
       "0    6    62.1      0       1          0\n",
       "1   18    74.7      1       0          0\n",
       "2   16    69.7      0       0          1\n",
       "3   14    71.0      0       1          0\n",
       "4    5    56.9      0       1          0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcn_x = lcn.iloc[:,[1,2,3,4,5]]\n",
    "lcn_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcn_y = lcn.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6.475\n",
       "1    10.125\n",
       "2     9.550\n",
       "3    11.125\n",
       "4     4.800\n",
       "Name: LungCap, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcn_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAMPLING\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lcn_x_train, lcn_x_test,lcn_y_train, lcn_y_test = train_test_split(lcn_x, lcn_y, test_size= 0.2 , random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "580/580 [==============================] - 1s 1ms/sample - loss: 5.9538 - mean_absolute_error: 1.8893 - mean_squared_error: 5.9538\n",
      "Epoch 2/500\n",
      "580/580 [==============================] - 0s 181us/sample - loss: 4.4677 - mean_absolute_error: 1.7181 - mean_squared_error: 4.4677\n",
      "Epoch 3/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 3.5274 - mean_absolute_error: 1.4980 - mean_squared_error: 3.5274\n",
      "Epoch 4/500\n",
      "580/580 [==============================] - 0s 300us/sample - loss: 3.1013 - mean_absolute_error: 1.4075 - mean_squared_error: 3.1013\n",
      "Epoch 5/500\n",
      "580/580 [==============================] - 0s 248us/sample - loss: 3.9576 - mean_absolute_error: 1.6195 - mean_squared_error: 3.9576\n",
      "Epoch 6/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 2.6220 - mean_absolute_error: 1.3005 - mean_squared_error: 2.6220\n",
      "Epoch 7/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 3.3512 - mean_absolute_error: 1.5033 - mean_squared_error: 3.3512\n",
      "Epoch 8/500\n",
      "580/580 [==============================] - 0s 148us/sample - loss: 2.4123 - mean_absolute_error: 1.2229 - mean_squared_error: 2.4123\n",
      "Epoch 9/500\n",
      "580/580 [==============================] - 0s 409us/sample - loss: 3.1601 - mean_absolute_error: 1.3999 - mean_squared_error: 3.1601\n",
      "Epoch 10/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 2.8784 - mean_absolute_error: 1.3517 - mean_squared_error: 2.8784\n",
      "Epoch 11/500\n",
      "580/580 [==============================] - 0s 119us/sample - loss: 3.0084 - mean_absolute_error: 1.3828 - mean_squared_error: 3.0084\n",
      "Epoch 12/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 2.6365 - mean_absolute_error: 1.2934 - mean_squared_error: 2.6365\n",
      "Epoch 13/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 2.5622 - mean_absolute_error: 1.2714 - mean_squared_error: 2.5622\n",
      "Epoch 14/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 2.7736 - mean_absolute_error: 1.3360 - mean_squared_error: 2.7736\n",
      "Epoch 15/500\n",
      "580/580 [==============================] - 0s 373us/sample - loss: 2.6559 - mean_absolute_error: 1.3239 - mean_squared_error: 2.6559\n",
      "Epoch 16/500\n",
      "580/580 [==============================] - 0s 167us/sample - loss: 2.6700 - mean_absolute_error: 1.2974 - mean_squared_error: 2.6700\n",
      "Epoch 17/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 2.2844 - mean_absolute_error: 1.2022 - mean_squared_error: 2.2844\n",
      "Epoch 18/500\n",
      "580/580 [==============================] - 0s 163us/sample - loss: 2.4435 - mean_absolute_error: 1.2522 - mean_squared_error: 2.4435\n",
      "Epoch 19/500\n",
      "580/580 [==============================] - 0s 113us/sample - loss: 2.7547 - mean_absolute_error: 1.3513 - mean_squared_error: 2.7547\n",
      "Epoch 20/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 2.4205 - mean_absolute_error: 1.2299 - mean_squared_error: 2.4205\n",
      "Epoch 21/500\n",
      "580/580 [==============================] - 0s 346us/sample - loss: 2.3115 - mean_absolute_error: 1.1980 - mean_squared_error: 2.3115\n",
      "Epoch 22/500\n",
      "580/580 [==============================] - 0s 132us/sample - loss: 2.2584 - mean_absolute_error: 1.1803 - mean_squared_error: 2.2584\n",
      "Epoch 23/500\n",
      "580/580 [==============================] - 0s 249us/sample - loss: 2.4888 - mean_absolute_error: 1.2704 - mean_squared_error: 2.4888\n",
      "Epoch 24/500\n",
      "580/580 [==============================] - 0s 208us/sample - loss: 2.6600 - mean_absolute_error: 1.3273 - mean_squared_error: 2.6600\n",
      "Epoch 25/500\n",
      "580/580 [==============================] - 0s 93us/sample - loss: 2.4762 - mean_absolute_error: 1.2682 - mean_squared_error: 2.4762\n",
      "Epoch 26/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 2.3865 - mean_absolute_error: 1.2392 - mean_squared_error: 2.3865\n",
      "Epoch 27/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 2.3834 - mean_absolute_error: 1.2241 - mean_squared_error: 2.3834\n",
      "Epoch 28/500\n",
      "580/580 [==============================] - 0s 524us/sample - loss: 2.1378 - mean_absolute_error: 1.1663 - mean_squared_error: 2.1378\n",
      "Epoch 29/500\n",
      "580/580 [==============================] - 0s 163us/sample - loss: 2.7861 - mean_absolute_error: 1.3052 - mean_squared_error: 2.7861\n",
      "Epoch 30/500\n",
      "580/580 [==============================] - 0s 150us/sample - loss: 2.3760 - mean_absolute_error: 1.2321 - mean_squared_error: 2.3760\n",
      "Epoch 31/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 2.3255 - mean_absolute_error: 1.2082 - mean_squared_error: 2.3255\n",
      "Epoch 32/500\n",
      "580/580 [==============================] - 0s 132us/sample - loss: 2.2578 - mean_absolute_error: 1.1807 - mean_squared_error: 2.2578\n",
      "Epoch 33/500\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 2.2634 - mean_absolute_error: 1.2089 - mean_squared_error: 2.2634\n",
      "Epoch 34/500\n",
      "580/580 [==============================] - 0s 273us/sample - loss: 2.1985 - mean_absolute_error: 1.1898 - mean_squared_error: 2.1985\n",
      "Epoch 35/500\n",
      "580/580 [==============================] - 0s 175us/sample - loss: 2.1904 - mean_absolute_error: 1.1870 - mean_squared_error: 2.1904\n",
      "Epoch 36/500\n",
      "580/580 [==============================] - 0s 165us/sample - loss: 2.4579 - mean_absolute_error: 1.2424 - mean_squared_error: 2.4579\n",
      "Epoch 37/500\n",
      "580/580 [==============================] - 0s 169us/sample - loss: 2.2599 - mean_absolute_error: 1.2049 - mean_squared_error: 2.2599\n",
      "Epoch 38/500\n",
      "580/580 [==============================] - 0s 227us/sample - loss: 2.2731 - mean_absolute_error: 1.2026 - mean_squared_error: 2.2731\n",
      "Epoch 39/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 2.2834 - mean_absolute_error: 1.2102 - mean_squared_error: 2.2834\n",
      "Epoch 40/500\n",
      "580/580 [==============================] - 0s 578us/sample - loss: 2.1147 - mean_absolute_error: 1.1692 - mean_squared_error: 2.1147\n",
      "Epoch 41/500\n",
      "580/580 [==============================] - 0s 371us/sample - loss: 2.1110 - mean_absolute_error: 1.1583 - mean_squared_error: 2.1110\n",
      "Epoch 42/500\n",
      "580/580 [==============================] - 0s 303us/sample - loss: 2.3002 - mean_absolute_error: 1.2303 - mean_squared_error: 2.3002\n",
      "Epoch 43/500\n",
      "580/580 [==============================] - 0s 251us/sample - loss: 2.0757 - mean_absolute_error: 1.1438 - mean_squared_error: 2.0757\n",
      "Epoch 44/500\n",
      "580/580 [==============================] - 0s 134us/sample - loss: 2.2782 - mean_absolute_error: 1.1998 - mean_squared_error: 2.2782\n",
      "Epoch 45/500\n",
      "580/580 [==============================] - 0s 181us/sample - loss: 2.1344 - mean_absolute_error: 1.1577 - mean_squared_error: 2.1344\n",
      "Epoch 46/500\n",
      "580/580 [==============================] - 0s 313us/sample - loss: 2.0916 - mean_absolute_error: 1.1689 - mean_squared_error: 2.0916\n",
      "Epoch 47/500\n",
      "580/580 [==============================] - 0s 96us/sample - loss: 2.2069 - mean_absolute_error: 1.1641 - mean_squared_error: 2.2069\n",
      "Epoch 48/500\n",
      "580/580 [==============================] - 0s 186us/sample - loss: 2.2574 - mean_absolute_error: 1.2078 - mean_squared_error: 2.2574\n",
      "Epoch 49/500\n",
      "580/580 [==============================] - 0s 521us/sample - loss: 2.1006 - mean_absolute_error: 1.1558 - mean_squared_error: 2.1006\n",
      "Epoch 50/500\n",
      "580/580 [==============================] - 0s 143us/sample - loss: 1.9501 - mean_absolute_error: 1.1183 - mean_squared_error: 1.9501\n",
      "Epoch 51/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 2.0188 - mean_absolute_error: 1.1274 - mean_squared_error: 2.0188\n",
      "Epoch 52/500\n",
      "580/580 [==============================] - 0s 254us/sample - loss: 2.2076 - mean_absolute_error: 1.1791 - mean_squared_error: 2.2076\n",
      "Epoch 53/500\n",
      "580/580 [==============================] - 0s 340us/sample - loss: 2.0559 - mean_absolute_error: 1.1414 - mean_squared_error: 2.0559\n",
      "Epoch 54/500\n",
      "580/580 [==============================] - 0s 136us/sample - loss: 2.1938 - mean_absolute_error: 1.1869 - mean_squared_error: 2.1938\n",
      "Epoch 55/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 2.1673 - mean_absolute_error: 1.1712 - mean_squared_error: 2.1673\n",
      "Epoch 56/500\n",
      "580/580 [==============================] - 0s 122us/sample - loss: 2.0251 - mean_absolute_error: 1.1170 - mean_squared_error: 2.0251\n",
      "Epoch 57/500\n",
      "580/580 [==============================] - 0s 69us/sample - loss: 2.1019 - mean_absolute_error: 1.1630 - mean_squared_error: 2.1019\n",
      "Epoch 58/500\n",
      "580/580 [==============================] - 0s 359us/sample - loss: 2.1120 - mean_absolute_error: 1.1416 - mean_squared_error: 2.1120\n",
      "Epoch 59/500\n",
      "580/580 [==============================] - 0s 160us/sample - loss: 1.9409 - mean_absolute_error: 1.1064 - mean_squared_error: 1.9409\n",
      "Epoch 60/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 2.1537 - mean_absolute_error: 1.1804 - mean_squared_error: 2.1538\n",
      "Epoch 61/500\n",
      "580/580 [==============================] - 0s 79us/sample - loss: 2.0262 - mean_absolute_error: 1.1296 - mean_squared_error: 2.0262\n",
      "Epoch 62/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 2.0660 - mean_absolute_error: 1.1340 - mean_squared_error: 2.0660\n",
      "Epoch 63/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 2.0369 - mean_absolute_error: 1.1291 - mean_squared_error: 2.0369\n",
      "Epoch 64/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.9236 - mean_absolute_error: 1.1081 - mean_squared_error: 1.9236\n",
      "Epoch 65/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.9415 - mean_absolute_error: 1.0986 - mean_squared_error: 1.9415\n",
      "Epoch 66/500\n",
      "580/580 [==============================] - 0s 427us/sample - loss: 2.0463 - mean_absolute_error: 1.1453 - mean_squared_error: 2.0463\n",
      "Epoch 67/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.9321 - mean_absolute_error: 1.0946 - mean_squared_error: 1.9321\n",
      "Epoch 68/500\n",
      "580/580 [==============================] - 0s 96us/sample - loss: 2.1418 - mean_absolute_error: 1.1545 - mean_squared_error: 2.1418\n",
      "Epoch 69/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 2.0440 - mean_absolute_error: 1.1566 - mean_squared_error: 2.0440\n",
      "Epoch 70/500\n",
      "580/580 [==============================] - 0s 131us/sample - loss: 1.9475 - mean_absolute_error: 1.1271 - mean_squared_error: 1.9475\n",
      "Epoch 71/500\n",
      "580/580 [==============================] - 0s 139us/sample - loss: 2.0948 - mean_absolute_error: 1.1563 - mean_squared_error: 2.0948\n",
      "Epoch 72/500\n",
      "580/580 [==============================] - 0s 384us/sample - loss: 2.0633 - mean_absolute_error: 1.1358 - mean_squared_error: 2.0633\n",
      "Epoch 73/500\n",
      "580/580 [==============================] - 0s 268us/sample - loss: 2.0332 - mean_absolute_error: 1.1381 - mean_squared_error: 2.0332\n",
      "Epoch 74/500\n",
      "580/580 [==============================] - 0s 144us/sample - loss: 1.7935 - mean_absolute_error: 1.0684 - mean_squared_error: 1.7935\n",
      "Epoch 75/500\n",
      "580/580 [==============================] - 0s 117us/sample - loss: 2.2080 - mean_absolute_error: 1.1716 - mean_squared_error: 2.2080\n",
      "Epoch 76/500\n",
      "580/580 [==============================] - 0s 119us/sample - loss: 1.7530 - mean_absolute_error: 1.0457 - mean_squared_error: 1.7530\n",
      "Epoch 77/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.8592 - mean_absolute_error: 1.0764 - mean_squared_error: 1.8592\n",
      "Epoch 78/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.8310 - mean_absolute_error: 1.0878 - mean_squared_error: 1.8310\n",
      "Epoch 79/500\n",
      "580/580 [==============================] - 0s 382us/sample - loss: 1.8216 - mean_absolute_error: 1.0836 - mean_squared_error: 1.8216\n",
      "Epoch 80/500\n",
      "580/580 [==============================] - 0s 416us/sample - loss: 2.0639 - mean_absolute_error: 1.1502 - mean_squared_error: 2.0639\n",
      "Epoch 81/500\n",
      "580/580 [==============================] - 0s 342us/sample - loss: 1.9808 - mean_absolute_error: 1.1251 - mean_squared_error: 1.9808\n",
      "Epoch 82/500\n",
      "580/580 [==============================] - 0s 368us/sample - loss: 1.8241 - mean_absolute_error: 1.0632 - mean_squared_error: 1.8241\n",
      "Epoch 83/500\n",
      "580/580 [==============================] - 0s 139us/sample - loss: 1.7491 - mean_absolute_error: 1.0435 - mean_squared_error: 1.7491\n",
      "Epoch 84/500\n",
      "580/580 [==============================] - 0s 332us/sample - loss: 1.9834 - mean_absolute_error: 1.1480 - mean_squared_error: 1.9834\n",
      "Epoch 85/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.8895 - mean_absolute_error: 1.0832 - mean_squared_error: 1.8895\n",
      "Epoch 86/500\n",
      "580/580 [==============================] - 0s 323us/sample - loss: 1.8743 - mean_absolute_error: 1.0825 - mean_squared_error: 1.8743\n",
      "Epoch 87/500\n",
      "580/580 [==============================] - 0s 201us/sample - loss: 1.9293 - mean_absolute_error: 1.1096 - mean_squared_error: 1.9293\n",
      "Epoch 88/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.9416 - mean_absolute_error: 1.1108 - mean_squared_error: 1.9416\n",
      "Epoch 89/500\n",
      "580/580 [==============================] - 0s 373us/sample - loss: 1.7316 - mean_absolute_error: 1.0598 - mean_squared_error: 1.7316\n",
      "Epoch 90/500\n",
      "580/580 [==============================] - 0s 292us/sample - loss: 2.0371 - mean_absolute_error: 1.1436 - mean_squared_error: 2.0371\n",
      "Epoch 91/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.7404 - mean_absolute_error: 1.0506 - mean_squared_error: 1.7404\n",
      "Epoch 92/500\n",
      "580/580 [==============================] - 0s 248us/sample - loss: 1.8141 - mean_absolute_error: 1.0873 - mean_squared_error: 1.8141\n",
      "Epoch 93/500\n",
      "580/580 [==============================] - 0s 181us/sample - loss: 1.8013 - mean_absolute_error: 1.0643 - mean_squared_error: 1.8013\n",
      "Epoch 94/500\n",
      "580/580 [==============================] - 0s 260us/sample - loss: 1.8202 - mean_absolute_error: 1.0627 - mean_squared_error: 1.8202\n",
      "Epoch 95/500\n",
      "580/580 [==============================] - 0s 187us/sample - loss: 1.8407 - mean_absolute_error: 1.0765 - mean_squared_error: 1.8407\n",
      "Epoch 96/500\n",
      "580/580 [==============================] - 0s 315us/sample - loss: 1.8051 - mean_absolute_error: 1.0607 - mean_squared_error: 1.8051\n",
      "Epoch 97/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.7932 - mean_absolute_error: 1.0571 - mean_squared_error: 1.7932\n",
      "Epoch 98/500\n",
      "580/580 [==============================] - 0s 131us/sample - loss: 1.8521 - mean_absolute_error: 1.0888 - mean_squared_error: 1.8521\n",
      "Epoch 99/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.7972 - mean_absolute_error: 1.0673 - mean_squared_error: 1.7972\n",
      "Epoch 100/500\n",
      "580/580 [==============================] - 0s 308us/sample - loss: 1.6982 - mean_absolute_error: 1.0359 - mean_squared_error: 1.6982\n",
      "Epoch 101/500\n",
      "580/580 [==============================] - 0s 346us/sample - loss: 1.7698 - mean_absolute_error: 1.0577 - mean_squared_error: 1.7698\n",
      "Epoch 102/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.8283 - mean_absolute_error: 1.0816 - mean_squared_error: 1.8283\n",
      "Epoch 103/500\n",
      "580/580 [==============================] - 0s 174us/sample - loss: 1.7198 - mean_absolute_error: 1.0429 - mean_squared_error: 1.7198\n",
      "Epoch 104/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.8030 - mean_absolute_error: 1.0817 - mean_squared_error: 1.8030\n",
      "Epoch 105/500\n",
      "580/580 [==============================] - 0s 534us/sample - loss: 1.8673 - mean_absolute_error: 1.0824 - mean_squared_error: 1.8673\n",
      "Epoch 106/500\n",
      "580/580 [==============================] - 0s 150us/sample - loss: 1.7599 - mean_absolute_error: 1.0478 - mean_squared_error: 1.7599\n",
      "Epoch 107/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.7770 - mean_absolute_error: 1.0485 - mean_squared_error: 1.7770\n",
      "Epoch 108/500\n",
      "580/580 [==============================] - 0s 136us/sample - loss: 1.8143 - mean_absolute_error: 1.0748 - mean_squared_error: 1.8143\n",
      "Epoch 109/500\n",
      "580/580 [==============================] - 0s 113us/sample - loss: 1.6752 - mean_absolute_error: 1.0257 - mean_squared_error: 1.6752\n",
      "Epoch 110/500\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 1.7272 - mean_absolute_error: 1.0298 - mean_squared_error: 1.7272\n",
      "Epoch 111/500\n",
      "580/580 [==============================] - 0s 346us/sample - loss: 1.7248 - mean_absolute_error: 1.0404 - mean_squared_error: 1.7248\n",
      "Epoch 112/500\n",
      "580/580 [==============================] - 0s 296us/sample - loss: 1.7432 - mean_absolute_error: 1.0559 - mean_squared_error: 1.7432\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 0s 366us/sample - loss: 1.7252 - mean_absolute_error: 1.0464 - mean_squared_error: 1.7252\n",
      "Epoch 114/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.6805 - mean_absolute_error: 1.0373 - mean_squared_error: 1.6805\n",
      "Epoch 115/500\n",
      "580/580 [==============================] - 0s 445us/sample - loss: 1.5864 - mean_absolute_error: 1.0177 - mean_squared_error: 1.5864\n",
      "Epoch 116/500\n",
      "580/580 [==============================] - 0s 397us/sample - loss: 1.7704 - mean_absolute_error: 1.0659 - mean_squared_error: 1.7704\n",
      "Epoch 117/500\n",
      "580/580 [==============================] - 0s 199us/sample - loss: 1.6676 - mean_absolute_error: 1.0131 - mean_squared_error: 1.6676\n",
      "Epoch 118/500\n",
      "580/580 [==============================] - 0s 134us/sample - loss: 1.8662 - mean_absolute_error: 1.0962 - mean_squared_error: 1.8662\n",
      "Epoch 119/500\n",
      "580/580 [==============================] - 0s 285us/sample - loss: 1.6590 - mean_absolute_error: 1.0219 - mean_squared_error: 1.6590\n",
      "Epoch 120/500\n",
      "580/580 [==============================] - 0s 139us/sample - loss: 1.6818 - mean_absolute_error: 1.0342 - mean_squared_error: 1.6818\n",
      "Epoch 121/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.7848 - mean_absolute_error: 1.0649 - mean_squared_error: 1.7848\n",
      "Epoch 122/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.6799 - mean_absolute_error: 1.0288 - mean_squared_error: 1.6799\n",
      "Epoch 123/500\n",
      "580/580 [==============================] - 0s 405us/sample - loss: 1.8579 - mean_absolute_error: 1.0803 - mean_squared_error: 1.8579\n",
      "Epoch 124/500\n",
      "580/580 [==============================] - 0s 151us/sample - loss: 1.6917 - mean_absolute_error: 1.0374 - mean_squared_error: 1.6917\n",
      "Epoch 125/500\n",
      "580/580 [==============================] - 0s 170us/sample - loss: 1.6376 - mean_absolute_error: 1.0104 - mean_squared_error: 1.6376\n",
      "Epoch 126/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 1.6784 - mean_absolute_error: 1.0321 - mean_squared_error: 1.6784\n",
      "Epoch 127/500\n",
      "580/580 [==============================] - 0s 325us/sample - loss: 1.6425 - mean_absolute_error: 1.0199 - mean_squared_error: 1.6425\n",
      "Epoch 128/500\n",
      "580/580 [==============================] - 0s 320us/sample - loss: 1.6511 - mean_absolute_error: 1.0299 - mean_squared_error: 1.6511\n",
      "Epoch 129/500\n",
      "580/580 [==============================] - ETA: 0s - loss: 3.6373 - mean_absolute_error: 1.5812 - mean_squared_error: 3.63 - 0s 88us/sample - loss: 1.6200 - mean_absolute_error: 1.0008 - mean_squared_error: 1.6200\n",
      "Epoch 130/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.6981 - mean_absolute_error: 1.0493 - mean_squared_error: 1.6981\n",
      "Epoch 131/500\n",
      "580/580 [==============================] - 0s 306us/sample - loss: 1.6998 - mean_absolute_error: 1.0379 - mean_squared_error: 1.6998\n",
      "Epoch 132/500\n",
      "580/580 [==============================] - 0s 107us/sample - loss: 1.7629 - mean_absolute_error: 1.0570 - mean_squared_error: 1.7629\n",
      "Epoch 133/500\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 1.6043 - mean_absolute_error: 1.0094 - mean_squared_error: 1.6043\n",
      "Epoch 134/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.6793 - mean_absolute_error: 1.0267 - mean_squared_error: 1.6793\n",
      "Epoch 135/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.7254 - mean_absolute_error: 1.0570 - mean_squared_error: 1.7254\n",
      "Epoch 136/500\n",
      "580/580 [==============================] - 0s 328us/sample - loss: 1.6030 - mean_absolute_error: 1.0157 - mean_squared_error: 1.6030\n",
      "Epoch 137/500\n",
      "580/580 [==============================] - 0s 170us/sample - loss: 1.7224 - mean_absolute_error: 1.0423 - mean_squared_error: 1.7224\n",
      "Epoch 138/500\n",
      "580/580 [==============================] - 0s 299us/sample - loss: 1.6898 - mean_absolute_error: 1.0371 - mean_squared_error: 1.6898\n",
      "Epoch 139/500\n",
      "580/580 [==============================] - 0s 151us/sample - loss: 1.7282 - mean_absolute_error: 1.0455 - mean_squared_error: 1.7282\n",
      "Epoch 140/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.6423 - mean_absolute_error: 1.0131 - mean_squared_error: 1.6423\n",
      "Epoch 141/500\n",
      "580/580 [==============================] - 0s 351us/sample - loss: 1.6143 - mean_absolute_error: 1.0167 - mean_squared_error: 1.6143\n",
      "Epoch 142/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.6418 - mean_absolute_error: 1.0105 - mean_squared_error: 1.6418\n",
      "Epoch 143/500\n",
      "580/580 [==============================] - 0s 81us/sample - loss: 1.6127 - mean_absolute_error: 1.0175 - mean_squared_error: 1.6127\n",
      "Epoch 144/500\n",
      "580/580 [==============================] - 0s 132us/sample - loss: 1.5841 - mean_absolute_error: 1.0033 - mean_squared_error: 1.5841\n",
      "Epoch 145/500\n",
      "580/580 [==============================] - 0s 311us/sample - loss: 1.6393 - mean_absolute_error: 1.0222 - mean_squared_error: 1.6393\n",
      "Epoch 146/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.6240 - mean_absolute_error: 1.0232 - mean_squared_error: 1.6240\n",
      "Epoch 147/500\n",
      "580/580 [==============================] - 0s 136us/sample - loss: 1.6903 - mean_absolute_error: 1.0486 - mean_squared_error: 1.6903\n",
      "Epoch 148/500\n",
      "580/580 [==============================] - 0s 360us/sample - loss: 1.6278 - mean_absolute_error: 1.0254 - mean_squared_error: 1.6278\n",
      "Epoch 149/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.6535 - mean_absolute_error: 1.0264 - mean_squared_error: 1.6535\n",
      "Epoch 150/500\n",
      "580/580 [==============================] - 0s 175us/sample - loss: 1.5444 - mean_absolute_error: 0.9816 - mean_squared_error: 1.5444\n",
      "Epoch 151/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.6954 - mean_absolute_error: 1.0203 - mean_squared_error: 1.6954\n",
      "Epoch 152/500\n",
      "580/580 [==============================] - 0s 212us/sample - loss: 1.6493 - mean_absolute_error: 1.0336 - mean_squared_error: 1.6493\n",
      "Epoch 153/500\n",
      "580/580 [==============================] - 0s 208us/sample - loss: 1.5708 - mean_absolute_error: 1.0027 - mean_squared_error: 1.5708\n",
      "Epoch 154/500\n",
      "580/580 [==============================] - 0s 444us/sample - loss: 1.6189 - mean_absolute_error: 1.0256 - mean_squared_error: 1.6189\n",
      "Epoch 155/500\n",
      "580/580 [==============================] - 0s 494us/sample - loss: 1.6524 - mean_absolute_error: 1.0255 - mean_squared_error: 1.6524\n",
      "Epoch 156/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.4860 - mean_absolute_error: 0.9721 - mean_squared_error: 1.4860\n",
      "Epoch 157/500\n",
      "580/580 [==============================] - 0s 332us/sample - loss: 1.6258 - mean_absolute_error: 1.0203 - mean_squared_error: 1.6258\n",
      "Epoch 158/500\n",
      "580/580 [==============================] - 0s 249us/sample - loss: 1.7355 - mean_absolute_error: 1.0543 - mean_squared_error: 1.7355\n",
      "Epoch 159/500\n",
      "580/580 [==============================] - 0s 380us/sample - loss: 1.5293 - mean_absolute_error: 0.9799 - mean_squared_error: 1.5293\n",
      "Epoch 160/500\n",
      "580/580 [==============================] - 0s 347us/sample - loss: 1.5821 - mean_absolute_error: 0.9985 - mean_squared_error: 1.5821\n",
      "Epoch 161/500\n",
      "580/580 [==============================] - 0s 299us/sample - loss: 1.6705 - mean_absolute_error: 1.0249 - mean_squared_error: 1.6705\n",
      "Epoch 162/500\n",
      "580/580 [==============================] - 0s 69us/sample - loss: 1.5993 - mean_absolute_error: 1.0025 - mean_squared_error: 1.5993\n",
      "Epoch 163/500\n",
      "580/580 [==============================] - 0s 179us/sample - loss: 1.6348 - mean_absolute_error: 1.0211 - mean_squared_error: 1.6348\n",
      "Epoch 164/500\n",
      "580/580 [==============================] - 0s 402us/sample - loss: 1.6131 - mean_absolute_error: 1.0222 - mean_squared_error: 1.6131\n",
      "Epoch 165/500\n",
      "580/580 [==============================] - 0s 210us/sample - loss: 1.5633 - mean_absolute_error: 0.9996 - mean_squared_error: 1.5633\n",
      "Epoch 166/500\n",
      "580/580 [==============================] - 0s 148us/sample - loss: 1.5807 - mean_absolute_error: 0.9951 - mean_squared_error: 1.5807\n",
      "Epoch 167/500\n",
      "580/580 [==============================] - 0s 218us/sample - loss: 1.6412 - mean_absolute_error: 1.0180 - mean_squared_error: 1.6412\n",
      "Epoch 168/500\n",
      "580/580 [==============================] - 0s 220us/sample - loss: 1.6329 - mean_absolute_error: 1.0160 - mean_squared_error: 1.6329\n",
      "Epoch 169/500\n",
      "580/580 [==============================] - 0s 322us/sample - loss: 1.5960 - mean_absolute_error: 1.0160 - mean_squared_error: 1.5960\n",
      "Epoch 170/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.6524 - mean_absolute_error: 1.0255 - mean_squared_error: 1.6524\n",
      "Epoch 171/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.5104 - mean_absolute_error: 0.9747 - mean_squared_error: 1.5104\n",
      "Epoch 172/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.5967 - mean_absolute_error: 1.0145 - mean_squared_error: 1.5967\n",
      "Epoch 173/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 1.6059 - mean_absolute_error: 1.0256 - mean_squared_error: 1.6059\n",
      "Epoch 174/500\n",
      "580/580 [==============================] - 0s 273us/sample - loss: 1.5275 - mean_absolute_error: 0.9870 - mean_squared_error: 1.5275\n",
      "Epoch 175/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.5143 - mean_absolute_error: 0.9878 - mean_squared_error: 1.5143\n",
      "Epoch 176/500\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 1.4656 - mean_absolute_error: 0.9688 - mean_squared_error: 1.4656\n",
      "Epoch 177/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 1.6220 - mean_absolute_error: 1.0186 - mean_squared_error: 1.6220\n",
      "Epoch 178/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.5635 - mean_absolute_error: 1.0035 - mean_squared_error: 1.5635\n",
      "Epoch 179/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.5470 - mean_absolute_error: 0.9982 - mean_squared_error: 1.5470\n",
      "Epoch 180/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.5647 - mean_absolute_error: 1.0025 - mean_squared_error: 1.5647\n",
      "Epoch 181/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.5374 - mean_absolute_error: 0.9782 - mean_squared_error: 1.5374\n",
      "Epoch 182/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.4836 - mean_absolute_error: 0.9699 - mean_squared_error: 1.4836\n",
      "Epoch 183/500\n",
      "580/580 [==============================] - 0s 292us/sample - loss: 1.5258 - mean_absolute_error: 0.9718 - mean_squared_error: 1.5258\n",
      "Epoch 184/500\n",
      "580/580 [==============================] - 0s 370us/sample - loss: 1.6579 - mean_absolute_error: 1.0337 - mean_squared_error: 1.6579\n",
      "Epoch 185/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.5820 - mean_absolute_error: 0.9879 - mean_squared_error: 1.5820\n",
      "Epoch 186/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.4844 - mean_absolute_error: 0.9606 - mean_squared_error: 1.4844\n",
      "Epoch 187/500\n",
      "580/580 [==============================] - 0s 107us/sample - loss: 1.5399 - mean_absolute_error: 0.9885 - mean_squared_error: 1.5399\n",
      "Epoch 188/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.6048 - mean_absolute_error: 1.0126 - mean_squared_error: 1.6048\n",
      "Epoch 189/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.4608 - mean_absolute_error: 0.9643 - mean_squared_error: 1.4608\n",
      "Epoch 190/500\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 1.5903 - mean_absolute_error: 1.0253 - mean_squared_error: 1.5903\n",
      "Epoch 191/500\n",
      "580/580 [==============================] - 0s 340us/sample - loss: 1.5514 - mean_absolute_error: 0.9978 - mean_squared_error: 1.5514\n",
      "Epoch 192/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 1.4943 - mean_absolute_error: 0.9704 - mean_squared_error: 1.4943\n",
      "Epoch 193/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.4485 - mean_absolute_error: 0.9579 - mean_squared_error: 1.4485\n",
      "Epoch 194/500\n",
      "580/580 [==============================] - 0s 71us/sample - loss: 1.5120 - mean_absolute_error: 0.9824 - mean_squared_error: 1.5120\n",
      "Epoch 195/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.4716 - mean_absolute_error: 0.9783 - mean_squared_error: 1.4716\n",
      "Epoch 196/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.5093 - mean_absolute_error: 0.9810 - mean_squared_error: 1.5093\n",
      "Epoch 197/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.5545 - mean_absolute_error: 0.9895 - mean_squared_error: 1.5545\n",
      "Epoch 198/500\n",
      "580/580 [==============================] - 0s 117us/sample - loss: 1.5409 - mean_absolute_error: 0.9888 - mean_squared_error: 1.5409\n",
      "Epoch 199/500\n",
      "580/580 [==============================] - 0s 339us/sample - loss: 1.4608 - mean_absolute_error: 0.9589 - mean_squared_error: 1.4608\n",
      "Epoch 200/500\n",
      "580/580 [==============================] - 0s 425us/sample - loss: 1.5251 - mean_absolute_error: 0.9800 - mean_squared_error: 1.5251\n",
      "Epoch 201/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.5305 - mean_absolute_error: 0.9861 - mean_squared_error: 1.5305\n",
      "Epoch 202/500\n",
      "580/580 [==============================] - 0s 71us/sample - loss: 1.5091 - mean_absolute_error: 0.9772 - mean_squared_error: 1.5091\n",
      "Epoch 203/500\n",
      "580/580 [==============================] - 0s 373us/sample - loss: 1.4805 - mean_absolute_error: 0.9672 - mean_squared_error: 1.4805\n",
      "Epoch 204/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.5380 - mean_absolute_error: 0.9884 - mean_squared_error: 1.5380\n",
      "Epoch 205/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 1.4689 - mean_absolute_error: 0.9756 - mean_squared_error: 1.4689\n",
      "Epoch 206/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 1.4889 - mean_absolute_error: 0.9650 - mean_squared_error: 1.4889\n",
      "Epoch 207/500\n",
      "580/580 [==============================] - 0s 363us/sample - loss: 1.4882 - mean_absolute_error: 0.9740 - mean_squared_error: 1.4882\n",
      "Epoch 208/500\n",
      "580/580 [==============================] - 0s 184us/sample - loss: 1.4973 - mean_absolute_error: 0.9831 - mean_squared_error: 1.4973\n",
      "Epoch 209/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.5071 - mean_absolute_error: 0.9797 - mean_squared_error: 1.5071\n",
      "Epoch 210/500\n",
      "580/580 [==============================] - 0s 170us/sample - loss: 1.4257 - mean_absolute_error: 0.9489 - mean_squared_error: 1.4257\n",
      "Epoch 211/500\n",
      "580/580 [==============================] - 0s 325us/sample - loss: 1.4807 - mean_absolute_error: 0.9734 - mean_squared_error: 1.4807\n",
      "Epoch 212/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.4746 - mean_absolute_error: 0.9732 - mean_squared_error: 1.4746\n",
      "Epoch 213/500\n",
      "580/580 [==============================] - 0s 158us/sample - loss: 1.5139 - mean_absolute_error: 0.9837 - mean_squared_error: 1.5139\n",
      "Epoch 214/500\n",
      "580/580 [==============================] - 0s 206us/sample - loss: 1.4422 - mean_absolute_error: 0.9577 - mean_squared_error: 1.4422\n",
      "Epoch 215/500\n",
      "580/580 [==============================] - 0s 490us/sample - loss: 1.4996 - mean_absolute_error: 0.9777 - mean_squared_error: 1.4996\n",
      "Epoch 216/500\n",
      "580/580 [==============================] - 0s 174us/sample - loss: 1.4268 - mean_absolute_error: 0.9476 - mean_squared_error: 1.4268\n",
      "Epoch 217/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.4014 - mean_absolute_error: 0.9607 - mean_squared_error: 1.4014\n",
      "Epoch 218/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.4553 - mean_absolute_error: 0.9603 - mean_squared_error: 1.4553\n",
      "Epoch 219/500\n",
      "580/580 [==============================] - 0s 253us/sample - loss: 1.3905 - mean_absolute_error: 0.9400 - mean_squared_error: 1.3905\n",
      "Epoch 220/500\n",
      "580/580 [==============================] - 0s 175us/sample - loss: 1.4246 - mean_absolute_error: 0.9426 - mean_squared_error: 1.4246\n",
      "Epoch 221/500\n",
      "580/580 [==============================] - 0s 144us/sample - loss: 1.4449 - mean_absolute_error: 0.9765 - mean_squared_error: 1.4449\n",
      "Epoch 222/500\n",
      "580/580 [==============================] - 0s 175us/sample - loss: 1.5169 - mean_absolute_error: 1.0047 - mean_squared_error: 1.5169\n",
      "Epoch 223/500\n",
      "580/580 [==============================] - 0s 124us/sample - loss: 1.4318 - mean_absolute_error: 0.9514 - mean_squared_error: 1.4318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.4785 - mean_absolute_error: 0.9680 - mean_squared_error: 1.4785\n",
      "Epoch 225/500\n",
      "580/580 [==============================] - 0s 93us/sample - loss: 1.4986 - mean_absolute_error: 0.9718 - mean_squared_error: 1.4986\n",
      "Epoch 226/500\n",
      "580/580 [==============================] - 0s 380us/sample - loss: 1.3938 - mean_absolute_error: 0.9449 - mean_squared_error: 1.3938\n",
      "Epoch 227/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.4937 - mean_absolute_error: 0.9757 - mean_squared_error: 1.4937\n",
      "Epoch 228/500\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 1.4882 - mean_absolute_error: 0.9861 - mean_squared_error: 1.4882\n",
      "Epoch 229/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.4465 - mean_absolute_error: 0.9724 - mean_squared_error: 1.4465\n",
      "Epoch 230/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.4051 - mean_absolute_error: 0.9510 - mean_squared_error: 1.4051\n",
      "Epoch 231/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.4843 - mean_absolute_error: 0.9729 - mean_squared_error: 1.4843\n",
      "Epoch 232/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.3737 - mean_absolute_error: 0.9428 - mean_squared_error: 1.3737\n",
      "Epoch 233/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.4810 - mean_absolute_error: 0.9793 - mean_squared_error: 1.4810\n",
      "Epoch 234/500\n",
      "580/580 [==============================] - 0s 76us/sample - loss: 1.4340 - mean_absolute_error: 0.9523 - mean_squared_error: 1.4340\n",
      "Epoch 235/500\n",
      "580/580 [==============================] - 0s 65us/sample - loss: 1.4383 - mean_absolute_error: 0.9625 - mean_squared_error: 1.4383\n",
      "Epoch 236/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.3646 - mean_absolute_error: 0.9270 - mean_squared_error: 1.3646\n",
      "Epoch 237/500\n",
      "580/580 [==============================] - 0s 275us/sample - loss: 1.4339 - mean_absolute_error: 0.9537 - mean_squared_error: 1.4339\n",
      "Epoch 238/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 1.3994 - mean_absolute_error: 0.9449 - mean_squared_error: 1.3994\n",
      "Epoch 239/500\n",
      "580/580 [==============================] - 0s 217us/sample - loss: 1.5028 - mean_absolute_error: 0.9836 - mean_squared_error: 1.5028\n",
      "Epoch 240/500\n",
      "580/580 [==============================] - 0s 205us/sample - loss: 1.4160 - mean_absolute_error: 0.9470 - mean_squared_error: 1.4160\n",
      "Epoch 241/500\n",
      "580/580 [==============================] - 0s 72us/sample - loss: 1.4609 - mean_absolute_error: 0.9631 - mean_squared_error: 1.4609\n",
      "Epoch 242/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.3521 - mean_absolute_error: 0.9390 - mean_squared_error: 1.3521\n",
      "Epoch 243/500\n",
      "580/580 [==============================] - 0s 64us/sample - loss: 1.4109 - mean_absolute_error: 0.9364 - mean_squared_error: 1.4109\n",
      "Epoch 244/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.4880 - mean_absolute_error: 0.9823 - mean_squared_error: 1.4880\n",
      "Epoch 245/500\n",
      "580/580 [==============================] - 0s 79us/sample - loss: 1.3887 - mean_absolute_error: 0.9360 - mean_squared_error: 1.3887\n",
      "Epoch 246/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.4139 - mean_absolute_error: 0.9553 - mean_squared_error: 1.4139\n",
      "Epoch 247/500\n",
      "580/580 [==============================] - 0s 311us/sample - loss: 1.3258 - mean_absolute_error: 0.9211 - mean_squared_error: 1.3258\n",
      "Epoch 248/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.4636 - mean_absolute_error: 0.9520 - mean_squared_error: 1.4636\n",
      "Epoch 249/500\n",
      "580/580 [==============================] - 0s 306us/sample - loss: 1.4327 - mean_absolute_error: 0.9636 - mean_squared_error: 1.4327\n",
      "Epoch 250/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.5180 - mean_absolute_error: 0.9856 - mean_squared_error: 1.5180\n",
      "Epoch 251/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 1.4068 - mean_absolute_error: 0.9463 - mean_squared_error: 1.4068\n",
      "Epoch 252/500\n",
      "580/580 [==============================] - 0s 368us/sample - loss: 1.4724 - mean_absolute_error: 0.9607 - mean_squared_error: 1.4724\n",
      "Epoch 253/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.4073 - mean_absolute_error: 0.9527 - mean_squared_error: 1.4073\n",
      "Epoch 254/500\n",
      "580/580 [==============================] - 0s 425us/sample - loss: 1.3794 - mean_absolute_error: 0.9324 - mean_squared_error: 1.3794\n",
      "Epoch 255/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.3451 - mean_absolute_error: 0.9375 - mean_squared_error: 1.3451\n",
      "Epoch 256/500\n",
      "580/580 [==============================] - 0s 285us/sample - loss: 1.3465 - mean_absolute_error: 0.9336 - mean_squared_error: 1.3465\n",
      "Epoch 257/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.4609 - mean_absolute_error: 0.9735 - mean_squared_error: 1.4609\n",
      "Epoch 258/500\n",
      "580/580 [==============================] - 0s 327us/sample - loss: 1.3325 - mean_absolute_error: 0.9263 - mean_squared_error: 1.3325\n",
      "Epoch 259/500\n",
      "580/580 [==============================] - 0s 277us/sample - loss: 1.4042 - mean_absolute_error: 0.9329 - mean_squared_error: 1.4042\n",
      "Epoch 260/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 1.3966 - mean_absolute_error: 0.9329 - mean_squared_error: 1.3966\n",
      "Epoch 261/500\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 1.4400 - mean_absolute_error: 0.9649 - mean_squared_error: 1.4400\n",
      "Epoch 262/500\n",
      "580/580 [==============================] - 0s 203us/sample - loss: 1.3534 - mean_absolute_error: 0.9265 - mean_squared_error: 1.3534\n",
      "Epoch 263/500\n",
      "580/580 [==============================] - 0s 389us/sample - loss: 1.4401 - mean_absolute_error: 0.9663 - mean_squared_error: 1.4401\n",
      "Epoch 264/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.3425 - mean_absolute_error: 0.9306 - mean_squared_error: 1.3425\n",
      "Epoch 265/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.3981 - mean_absolute_error: 0.9570 - mean_squared_error: 1.3981\n",
      "Epoch 266/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.3738 - mean_absolute_error: 0.9365 - mean_squared_error: 1.3738\n",
      "Epoch 267/500\n",
      "580/580 [==============================] - 0s 79us/sample - loss: 1.3841 - mean_absolute_error: 0.9460 - mean_squared_error: 1.3841\n",
      "Epoch 268/500\n",
      "580/580 [==============================] - 0s 411us/sample - loss: 1.4511 - mean_absolute_error: 0.9691 - mean_squared_error: 1.4511\n",
      "Epoch 269/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.3280 - mean_absolute_error: 0.9165 - mean_squared_error: 1.3280\n",
      "Epoch 270/500\n",
      "580/580 [==============================] - 0s 143us/sample - loss: 1.3992 - mean_absolute_error: 0.9395 - mean_squared_error: 1.3992\n",
      "Epoch 271/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.3907 - mean_absolute_error: 0.9532 - mean_squared_error: 1.3907\n",
      "Epoch 272/500\n",
      "580/580 [==============================] - 0s 148us/sample - loss: 1.3317 - mean_absolute_error: 0.9283 - mean_squared_error: 1.3317\n",
      "Epoch 273/500\n",
      "580/580 [==============================] - 0s 454us/sample - loss: 1.4255 - mean_absolute_error: 0.9560 - mean_squared_error: 1.4255 - loss: 1.6503 - mean_absolute_error: 1.0420 - mean_squared_error\n",
      "Epoch 274/500\n",
      "580/580 [==============================] - 0s 155us/sample - loss: 1.2737 - mean_absolute_error: 0.9058 - mean_squared_error: 1.2737\n",
      "Epoch 275/500\n",
      "580/580 [==============================] - 0s 160us/sample - loss: 1.4167 - mean_absolute_error: 0.9460 - mean_squared_error: 1.4167\n",
      "Epoch 276/500\n",
      "580/580 [==============================] - 0s 134us/sample - loss: 1.3967 - mean_absolute_error: 0.9417 - mean_squared_error: 1.3967\n",
      "Epoch 277/500\n",
      "580/580 [==============================] - 0s 155us/sample - loss: 1.3415 - mean_absolute_error: 0.9351 - mean_squared_error: 1.3415\n",
      "Epoch 278/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.4171 - mean_absolute_error: 0.9514 - mean_squared_error: 1.4171\n",
      "Epoch 279/500\n",
      "580/580 [==============================] - 0s 421us/sample - loss: 1.2777 - mean_absolute_error: 0.9125 - mean_squared_error: 1.2777\n",
      "Epoch 280/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.4388 - mean_absolute_error: 0.9458 - mean_squared_error: 1.4388\n",
      "Epoch 281/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.3528 - mean_absolute_error: 0.9365 - mean_squared_error: 1.3528\n",
      "Epoch 282/500\n",
      "580/580 [==============================] - 0s 119us/sample - loss: 1.3337 - mean_absolute_error: 0.9327 - mean_squared_error: 1.3337\n",
      "Epoch 283/500\n",
      "580/580 [==============================] - 0s 120us/sample - loss: 1.3365 - mean_absolute_error: 0.9232 - mean_squared_error: 1.3365\n",
      "Epoch 284/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.3632 - mean_absolute_error: 0.9304 - mean_squared_error: 1.3632\n",
      "Epoch 285/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.2597 - mean_absolute_error: 0.8993 - mean_squared_error: 1.2597\n",
      "Epoch 286/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 1.3850 - mean_absolute_error: 0.9432 - mean_squared_error: 1.3850\n",
      "Epoch 287/500\n",
      "580/580 [==============================] - 0s 502us/sample - loss: 1.3467 - mean_absolute_error: 0.9264 - mean_squared_error: 1.3467\n",
      "Epoch 288/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.3721 - mean_absolute_error: 0.9301 - mean_squared_error: 1.3721\n",
      "Epoch 289/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.3239 - mean_absolute_error: 0.9131 - mean_squared_error: 1.3239\n",
      "Epoch 290/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.3845 - mean_absolute_error: 0.9284 - mean_squared_error: 1.3845\n",
      "Epoch 291/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.4165 - mean_absolute_error: 0.9520 - mean_squared_error: 1.4165\n",
      "Epoch 292/500\n",
      "580/580 [==============================] - 0s 150us/sample - loss: 1.3087 - mean_absolute_error: 0.9223 - mean_squared_error: 1.3087\n",
      "Epoch 293/500\n",
      "580/580 [==============================] - 0s 107us/sample - loss: 1.4184 - mean_absolute_error: 0.9576 - mean_squared_error: 1.4184\n",
      "Epoch 294/500\n",
      "580/580 [==============================] - 0s 344us/sample - loss: 1.2915 - mean_absolute_error: 0.9133 - mean_squared_error: 1.2915\n",
      "Epoch 295/500\n",
      "580/580 [==============================] - 0s 435us/sample - loss: 1.4201 - mean_absolute_error: 0.9675 - mean_squared_error: 1.4201\n",
      "Epoch 296/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.2857 - mean_absolute_error: 0.9037 - mean_squared_error: 1.2857\n",
      "Epoch 297/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.3478 - mean_absolute_error: 0.9124 - mean_squared_error: 1.3478\n",
      "Epoch 298/500\n",
      "580/580 [==============================] - 0s 236us/sample - loss: 1.3068 - mean_absolute_error: 0.9139 - mean_squared_error: 1.3068\n",
      "Epoch 299/500\n",
      "580/580 [==============================] - 0s 198us/sample - loss: 1.3455 - mean_absolute_error: 0.9274 - mean_squared_error: 1.3455\n",
      "Epoch 300/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.2343 - mean_absolute_error: 0.8825 - mean_squared_error: 1.2343\n",
      "Epoch 301/500\n",
      "580/580 [==============================] - 0s 167us/sample - loss: 1.3870 - mean_absolute_error: 0.9360 - mean_squared_error: 1.3870\n",
      "Epoch 302/500\n",
      "580/580 [==============================] - 0s 454us/sample - loss: 1.3453 - mean_absolute_error: 0.9252 - mean_squared_error: 1.3453\n",
      "Epoch 303/500\n",
      "580/580 [==============================] - 0s 132us/sample - loss: 1.2479 - mean_absolute_error: 0.8949 - mean_squared_error: 1.2479\n",
      "Epoch 304/500\n",
      "580/580 [==============================] - 0s 491us/sample - loss: 1.2908 - mean_absolute_error: 0.9091 - mean_squared_error: 1.2908\n",
      "Epoch 305/500\n",
      "580/580 [==============================] - 0s 296us/sample - loss: 1.3028 - mean_absolute_error: 0.9016 - mean_squared_error: 1.3028\n",
      "Epoch 306/500\n",
      "580/580 [==============================] - 0s 254us/sample - loss: 1.3742 - mean_absolute_error: 0.9350 - mean_squared_error: 1.3742\n",
      "Epoch 307/500\n",
      "580/580 [==============================] - 0s 155us/sample - loss: 1.3172 - mean_absolute_error: 0.9122 - mean_squared_error: 1.3172\n",
      "Epoch 308/500\n",
      "580/580 [==============================] - 0s 587us/sample - loss: 1.2689 - mean_absolute_error: 0.8980 - mean_squared_error: 1.2689\n",
      "Epoch 309/500\n",
      "580/580 [==============================] - 0s 367us/sample - loss: 1.3922 - mean_absolute_error: 0.9495 - mean_squared_error: 1.3922\n",
      "Epoch 310/500\n",
      "580/580 [==============================] - 0s 382us/sample - loss: 1.2721 - mean_absolute_error: 0.8930 - mean_squared_error: 1.2721\n",
      "Epoch 311/500\n",
      "580/580 [==============================] - 0s 162us/sample - loss: 1.3371 - mean_absolute_error: 0.9161 - mean_squared_error: 1.3371\n",
      "Epoch 312/500\n",
      "580/580 [==============================] - 0s 172us/sample - loss: 1.3805 - mean_absolute_error: 0.9456 - mean_squared_error: 1.3805\n",
      "Epoch 313/500\n",
      "580/580 [==============================] - 0s 320us/sample - loss: 1.3010 - mean_absolute_error: 0.9099 - mean_squared_error: 1.3010\n",
      "Epoch 314/500\n",
      "580/580 [==============================] - 0s 370us/sample - loss: 1.3062 - mean_absolute_error: 0.9165 - mean_squared_error: 1.3062\n",
      "Epoch 315/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.3262 - mean_absolute_error: 0.9350 - mean_squared_error: 1.3262\n",
      "Epoch 316/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.3039 - mean_absolute_error: 0.9216 - mean_squared_error: 1.3039\n",
      "Epoch 317/500\n",
      "580/580 [==============================] - 0s 117us/sample - loss: 1.2541 - mean_absolute_error: 0.8974 - mean_squared_error: 1.2541\n",
      "Epoch 318/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.3073 - mean_absolute_error: 0.9271 - mean_squared_error: 1.3073\n",
      "Epoch 319/500\n",
      "580/580 [==============================] - 0s 119us/sample - loss: 1.2911 - mean_absolute_error: 0.9273 - mean_squared_error: 1.2911\n",
      "Epoch 320/500\n",
      "580/580 [==============================] - 0s 124us/sample - loss: 1.2288 - mean_absolute_error: 0.8826 - mean_squared_error: 1.2288\n",
      "Epoch 321/500\n",
      "580/580 [==============================] - 0s 408us/sample - loss: 1.3109 - mean_absolute_error: 0.9233 - mean_squared_error: 1.3109\n",
      "Epoch 322/500\n",
      "580/580 [==============================] - 0s 193us/sample - loss: 1.2477 - mean_absolute_error: 0.9061 - mean_squared_error: 1.2477\n",
      "Epoch 323/500\n",
      "580/580 [==============================] - 0s 113us/sample - loss: 1.2666 - mean_absolute_error: 0.8889 - mean_squared_error: 1.2666\n",
      "Epoch 324/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.4455 - mean_absolute_error: 0.9546 - mean_squared_error: 1.4455\n",
      "Epoch 325/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.2307 - mean_absolute_error: 0.8967 - mean_squared_error: 1.2307\n",
      "Epoch 326/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.2155 - mean_absolute_error: 0.8805 - mean_squared_error: 1.2155\n",
      "Epoch 327/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.3476 - mean_absolute_error: 0.9479 - mean_squared_error: 1.3476\n",
      "Epoch 328/500\n",
      "580/580 [==============================] - 0s 81us/sample - loss: 1.2704 - mean_absolute_error: 0.8998 - mean_squared_error: 1.2704\n",
      "Epoch 329/500\n",
      "580/580 [==============================] - 0s 349us/sample - loss: 1.2548 - mean_absolute_error: 0.8948 - mean_squared_error: 1.2548\n",
      "Epoch 330/500\n",
      "580/580 [==============================] - 0s 280us/sample - loss: 1.3061 - mean_absolute_error: 0.9080 - mean_squared_error: 1.3061\n",
      "Epoch 331/500\n",
      "580/580 [==============================] - 0s 146us/sample - loss: 1.2502 - mean_absolute_error: 0.8959 - mean_squared_error: 1.2502\n",
      "Epoch 332/500\n",
      "580/580 [==============================] - 0s 169us/sample - loss: 1.2628 - mean_absolute_error: 0.8953 - mean_squared_error: 1.2628\n",
      "Epoch 333/500\n",
      "580/580 [==============================] - 0s 338us/sample - loss: 1.3437 - mean_absolute_error: 0.9348 - mean_squared_error: 1.3437\n",
      "Epoch 334/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 0s 420us/sample - loss: 1.2372 - mean_absolute_error: 0.8859 - mean_squared_error: 1.2372\n",
      "Epoch 335/500\n",
      "580/580 [==============================] - 0s 342us/sample - loss: 1.2551 - mean_absolute_error: 0.9001 - mean_squared_error: 1.2551\n",
      "Epoch 336/500\n",
      "580/580 [==============================] - 0s 215us/sample - loss: 1.2413 - mean_absolute_error: 0.8919 - mean_squared_error: 1.2413\n",
      "Epoch 337/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.2695 - mean_absolute_error: 0.9050 - mean_squared_error: 1.2695\n",
      "Epoch 338/500\n",
      "580/580 [==============================] - 0s 158us/sample - loss: 1.2571 - mean_absolute_error: 0.9048 - mean_squared_error: 1.2571\n",
      "Epoch 339/500\n",
      "580/580 [==============================] - 0s 387us/sample - loss: 1.3469 - mean_absolute_error: 0.9219 - mean_squared_error: 1.3469\n",
      "Epoch 340/500\n",
      "580/580 [==============================] - 0s 117us/sample - loss: 1.2500 - mean_absolute_error: 0.9010 - mean_squared_error: 1.2500\n",
      "Epoch 341/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.3022 - mean_absolute_error: 0.9168 - mean_squared_error: 1.3022\n",
      "Epoch 342/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.2885 - mean_absolute_error: 0.9189 - mean_squared_error: 1.2885\n",
      "Epoch 343/500\n",
      "580/580 [==============================] - 0s 459us/sample - loss: 1.2084 - mean_absolute_error: 0.8878 - mean_squared_error: 1.2084\n",
      "Epoch 344/500\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 1.3325 - mean_absolute_error: 0.9134 - mean_squared_error: 1.3325\n",
      "Epoch 345/500\n",
      "580/580 [==============================] - 0s 122us/sample - loss: 1.3141 - mean_absolute_error: 0.9193 - mean_squared_error: 1.3141\n",
      "Epoch 346/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 1.2618 - mean_absolute_error: 0.9011 - mean_squared_error: 1.2618\n",
      "Epoch 347/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 1.2231 - mean_absolute_error: 0.8948 - mean_squared_error: 1.2231\n",
      "Epoch 348/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.2746 - mean_absolute_error: 0.9025 - mean_squared_error: 1.2746\n",
      "Epoch 349/500\n",
      "580/580 [==============================] - 0s 346us/sample - loss: 1.3274 - mean_absolute_error: 0.9252 - mean_squared_error: 1.3274\n",
      "Epoch 350/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.1813 - mean_absolute_error: 0.8838 - mean_squared_error: 1.1813\n",
      "Epoch 351/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.2552 - mean_absolute_error: 0.8901 - mean_squared_error: 1.2552\n",
      "Epoch 352/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.2158 - mean_absolute_error: 0.8938 - mean_squared_error: 1.2158\n",
      "Epoch 353/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.1863 - mean_absolute_error: 0.8784 - mean_squared_error: 1.1863\n",
      "Epoch 354/500\n",
      "580/580 [==============================] - 0s 162us/sample - loss: 1.2107 - mean_absolute_error: 0.8888 - mean_squared_error: 1.2107\n",
      "Epoch 355/500\n",
      "580/580 [==============================] - 0s 404us/sample - loss: 1.2635 - mean_absolute_error: 0.9126 - mean_squared_error: 1.2635\n",
      "Epoch 356/500\n",
      "580/580 [==============================] - 0s 153us/sample - loss: 1.2883 - mean_absolute_error: 0.9130 - mean_squared_error: 1.2883\n",
      "Epoch 357/500\n",
      "580/580 [==============================] - 0s 160us/sample - loss: 1.2664 - mean_absolute_error: 0.9023 - mean_squared_error: 1.2664\n",
      "Epoch 358/500\n",
      "580/580 [==============================] - 0s 177us/sample - loss: 1.2224 - mean_absolute_error: 0.8868 - mean_squared_error: 1.2224\n",
      "Epoch 359/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.1414 - mean_absolute_error: 0.8598 - mean_squared_error: 1.1414\n",
      "Epoch 360/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.2475 - mean_absolute_error: 0.9014 - mean_squared_error: 1.2475\n",
      "Epoch 361/500\n",
      "580/580 [==============================] - 0s 359us/sample - loss: 1.2808 - mean_absolute_error: 0.9040 - mean_squared_error: 1.2808\n",
      "Epoch 362/500\n",
      "580/580 [==============================] - 0s 234us/sample - loss: 1.1907 - mean_absolute_error: 0.8741 - mean_squared_error: 1.1907\n",
      "Epoch 363/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 1.2979 - mean_absolute_error: 0.8976 - mean_squared_error: 1.2979\n",
      "Epoch 364/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.2268 - mean_absolute_error: 0.8950 - mean_squared_error: 1.2268\n",
      "Epoch 365/500\n",
      "580/580 [==============================] - 0s 146us/sample - loss: 1.1155 - mean_absolute_error: 0.8453 - mean_squared_error: 1.1155\n",
      "Epoch 366/500\n",
      "580/580 [==============================] - 0s 172us/sample - loss: 1.3433 - mean_absolute_error: 0.9335 - mean_squared_error: 1.3433\n",
      "Epoch 367/500\n",
      "580/580 [==============================] - 0s 194us/sample - loss: 1.2398 - mean_absolute_error: 0.8952 - mean_squared_error: 1.2398\n",
      "Epoch 368/500\n",
      "580/580 [==============================] - 0s 459us/sample - loss: 1.2081 - mean_absolute_error: 0.8914 - mean_squared_error: 1.2081\n",
      "Epoch 369/500\n",
      "580/580 [==============================] - 0s 182us/sample - loss: 1.2658 - mean_absolute_error: 0.8932 - mean_squared_error: 1.2658\n",
      "Epoch 370/500\n",
      "580/580 [==============================] - 0s 282us/sample - loss: 1.1766 - mean_absolute_error: 0.8787 - mean_squared_error: 1.1766\n",
      "Epoch 371/500\n",
      "580/580 [==============================] - 0s 463us/sample - loss: 1.3595 - mean_absolute_error: 0.9092 - mean_squared_error: 1.3595\n",
      "Epoch 372/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.2441 - mean_absolute_error: 0.9010 - mean_squared_error: 1.2441\n",
      "Epoch 373/500\n",
      "580/580 [==============================] - 0s 349us/sample - loss: 1.2238 - mean_absolute_error: 0.8901 - mean_squared_error: 1.2238\n",
      "Epoch 374/500\n",
      "580/580 [==============================] - 0s 150us/sample - loss: 1.2402 - mean_absolute_error: 0.8951 - mean_squared_error: 1.2402\n",
      "Epoch 375/500\n",
      "580/580 [==============================] - 0s 409us/sample - loss: 1.2259 - mean_absolute_error: 0.8981 - mean_squared_error: 1.2259\n",
      "Epoch 376/500\n",
      "580/580 [==============================] - 0s 162us/sample - loss: 1.2154 - mean_absolute_error: 0.8820 - mean_squared_error: 1.2154\n",
      "Epoch 377/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.2969 - mean_absolute_error: 0.8972 - mean_squared_error: 1.2969\n",
      "Epoch 378/500\n",
      "580/580 [==============================] - 0s 424us/sample - loss: 1.1244 - mean_absolute_error: 0.8538 - mean_squared_error: 1.1244\n",
      "Epoch 379/500\n",
      "580/580 [==============================] - 0s 213us/sample - loss: 1.2912 - mean_absolute_error: 0.9172 - mean_squared_error: 1.2912\n",
      "Epoch 380/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.3015 - mean_absolute_error: 0.9286 - mean_squared_error: 1.3015\n",
      "Epoch 381/500\n",
      "580/580 [==============================] - 0s 329us/sample - loss: 1.1482 - mean_absolute_error: 0.8589 - mean_squared_error: 1.1482\n",
      "Epoch 382/500\n",
      "580/580 [==============================] - 0s 322us/sample - loss: 1.2663 - mean_absolute_error: 0.9096 - mean_squared_error: 1.2663\n",
      "Epoch 383/500\n",
      "580/580 [==============================] - 0s 177us/sample - loss: 1.1764 - mean_absolute_error: 0.8651 - mean_squared_error: 1.1764\n",
      "Epoch 384/500\n",
      "580/580 [==============================] - 0s 339us/sample - loss: 1.1299 - mean_absolute_error: 0.8645 - mean_squared_error: 1.1299\n",
      "Epoch 385/500\n",
      "580/580 [==============================] - 0s 119us/sample - loss: 1.2522 - mean_absolute_error: 0.9060 - mean_squared_error: 1.2522\n",
      "Epoch 386/500\n",
      "580/580 [==============================] - 0s 322us/sample - loss: 1.1292 - mean_absolute_error: 0.8579 - mean_squared_error: 1.1292\n",
      "Epoch 387/500\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 1.2418 - mean_absolute_error: 0.9040 - mean_squared_error: 1.2418\n",
      "Epoch 388/500\n",
      "580/580 [==============================] - 0s 181us/sample - loss: 1.2279 - mean_absolute_error: 0.8964 - mean_squared_error: 1.2279\n",
      "Epoch 389/500\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 1.2210 - mean_absolute_error: 0.8887 - mean_squared_error: 1.2210\n",
      "Epoch 390/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.2085 - mean_absolute_error: 0.8830 - mean_squared_error: 1.2085\n",
      "Epoch 391/500\n",
      "580/580 [==============================] - 0s 113us/sample - loss: 1.1568 - mean_absolute_error: 0.8588 - mean_squared_error: 1.1568\n",
      "Epoch 392/500\n",
      "580/580 [==============================] - 0s 304us/sample - loss: 1.1511 - mean_absolute_error: 0.8636 - mean_squared_error: 1.1511\n",
      "Epoch 393/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.2511 - mean_absolute_error: 0.8846 - mean_squared_error: 1.2511\n",
      "Epoch 394/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.2015 - mean_absolute_error: 0.8767 - mean_squared_error: 1.2015\n",
      "Epoch 395/500\n",
      "580/580 [==============================] - 0s 303us/sample - loss: 1.1548 - mean_absolute_error: 0.8651 - mean_squared_error: 1.1548\n",
      "Epoch 396/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.1821 - mean_absolute_error: 0.8590 - mean_squared_error: 1.1821\n",
      "Epoch 397/500\n",
      "580/580 [==============================] - 0s 74us/sample - loss: 1.2345 - mean_absolute_error: 0.8870 - mean_squared_error: 1.2345\n",
      "Epoch 398/500\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 1.2698 - mean_absolute_error: 0.9046 - mean_squared_error: 1.2698\n",
      "Epoch 399/500\n",
      "580/580 [==============================] - 0s 69us/sample - loss: 1.2033 - mean_absolute_error: 0.8812 - mean_squared_error: 1.2033\n",
      "Epoch 400/500\n",
      "580/580 [==============================] - 0s 69us/sample - loss: 1.2255 - mean_absolute_error: 0.9012 - mean_squared_error: 1.2255\n",
      "Epoch 401/500\n",
      "580/580 [==============================] - 0s 296us/sample - loss: 1.1586 - mean_absolute_error: 0.8690 - mean_squared_error: 1.1586\n",
      "Epoch 402/500\n",
      "580/580 [==============================] - 0s 151us/sample - loss: 1.2336 - mean_absolute_error: 0.9046 - mean_squared_error: 1.2336\n",
      "Epoch 403/500\n",
      "580/580 [==============================] - 0s 236us/sample - loss: 1.2441 - mean_absolute_error: 0.9015 - mean_squared_error: 1.2441\n",
      "Epoch 404/500\n",
      "580/580 [==============================] - 0s 175us/sample - loss: 1.2907 - mean_absolute_error: 0.8926 - mean_squared_error: 1.2907\n",
      "Epoch 405/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.2103 - mean_absolute_error: 0.8907 - mean_squared_error: 1.2103\n",
      "Epoch 406/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.1684 - mean_absolute_error: 0.8725 - mean_squared_error: 1.1684\n",
      "Epoch 407/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.1446 - mean_absolute_error: 0.8657 - mean_squared_error: 1.1446\n",
      "Epoch 408/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.2295 - mean_absolute_error: 0.9039 - mean_squared_error: 1.2295\n",
      "Epoch 409/500\n",
      "580/580 [==============================] - 0s 286us/sample - loss: 1.1762 - mean_absolute_error: 0.8718 - mean_squared_error: 1.1762\n",
      "Epoch 410/500\n",
      "580/580 [==============================] - 0s 153us/sample - loss: 1.2664 - mean_absolute_error: 0.9060 - mean_squared_error: 1.2664\n",
      "Epoch 411/500\n",
      "580/580 [==============================] - 0s 408us/sample - loss: 1.1090 - mean_absolute_error: 0.8439 - mean_squared_error: 1.1090\n",
      "Epoch 412/500\n",
      "580/580 [==============================] - 0s 126us/sample - loss: 1.2647 - mean_absolute_error: 0.9044 - mean_squared_error: 1.2647\n",
      "Epoch 413/500\n",
      "580/580 [==============================] - 0s 378us/sample - loss: 1.2235 - mean_absolute_error: 0.8914 - mean_squared_error: 1.2235\n",
      "Epoch 414/500\n",
      "580/580 [==============================] - 0s 115us/sample - loss: 1.1659 - mean_absolute_error: 0.8681 - mean_squared_error: 1.1659\n",
      "Epoch 415/500\n",
      "580/580 [==============================] - 0s 385us/sample - loss: 1.1571 - mean_absolute_error: 0.8676 - mean_squared_error: 1.1571\n",
      "Epoch 416/500\n",
      "580/580 [==============================] - 0s 191us/sample - loss: 1.2061 - mean_absolute_error: 0.8887 - mean_squared_error: 1.2061\n",
      "Epoch 417/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.1687 - mean_absolute_error: 0.8722 - mean_squared_error: 1.1687\n",
      "Epoch 418/500\n",
      "580/580 [==============================] - 0s 314us/sample - loss: 1.2112 - mean_absolute_error: 0.8815 - mean_squared_error: 1.2112\n",
      "Epoch 419/500\n",
      "580/580 [==============================] - 0s 217us/sample - loss: 1.2587 - mean_absolute_error: 0.8972 - mean_squared_error: 1.2587\n",
      "Epoch 420/500\n",
      "580/580 [==============================] - 0s 113us/sample - loss: 1.1433 - mean_absolute_error: 0.8437 - mean_squared_error: 1.1433\n",
      "Epoch 421/500\n",
      "580/580 [==============================] - 0s 239us/sample - loss: 1.0837 - mean_absolute_error: 0.8265 - mean_squared_error: 1.0837\n",
      "Epoch 422/500\n",
      "580/580 [==============================] - 0s 428us/sample - loss: 1.3003 - mean_absolute_error: 0.9105 - mean_squared_error: 1.3003\n",
      "Epoch 423/500\n",
      "580/580 [==============================] - 0s 107us/sample - loss: 1.1193 - mean_absolute_error: 0.8609 - mean_squared_error: 1.1193\n",
      "Epoch 424/500\n",
      "580/580 [==============================] - 0s 120us/sample - loss: 1.1231 - mean_absolute_error: 0.8631 - mean_squared_error: 1.1231\n",
      "Epoch 425/500\n",
      "580/580 [==============================] - 0s 308us/sample - loss: 1.2458 - mean_absolute_error: 0.9042 - mean_squared_error: 1.2458\n",
      "Epoch 426/500\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 1.2396 - mean_absolute_error: 0.9002 - mean_squared_error: 1.2396\n",
      "Epoch 427/500\n",
      "580/580 [==============================] - 0s 184us/sample - loss: 1.1429 - mean_absolute_error: 0.8671 - mean_squared_error: 1.1429\n",
      "Epoch 428/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.2471 - mean_absolute_error: 0.8824 - mean_squared_error: 1.2471\n",
      "Epoch 429/500\n",
      "580/580 [==============================] - 0s 334us/sample - loss: 1.1613 - mean_absolute_error: 0.8619 - mean_squared_error: 1.1613\n",
      "Epoch 430/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 1.1624 - mean_absolute_error: 0.8683 - mean_squared_error: 1.1624\n",
      "Epoch 431/500\n",
      "580/580 [==============================] - 0s 124us/sample - loss: 1.1229 - mean_absolute_error: 0.8475 - mean_squared_error: 1.1229\n",
      "Epoch 432/500\n",
      "580/580 [==============================] - 0s 323us/sample - loss: 1.1459 - mean_absolute_error: 0.8652 - mean_squared_error: 1.1459\n",
      "Epoch 433/500\n",
      "580/580 [==============================] - 0s 139us/sample - loss: 1.1259 - mean_absolute_error: 0.8369 - mean_squared_error: 1.1259\n",
      "Epoch 434/500\n",
      "580/580 [==============================] - 0s 310us/sample - loss: 1.2480 - mean_absolute_error: 0.9096 - mean_squared_error: 1.2480\n",
      "Epoch 435/500\n",
      "580/580 [==============================] - 0s 136us/sample - loss: 1.1203 - mean_absolute_error: 0.8502 - mean_squared_error: 1.1203\n",
      "Epoch 436/500\n",
      "580/580 [==============================] - 0s 138us/sample - loss: 1.2501 - mean_absolute_error: 0.9131 - mean_squared_error: 1.2501\n",
      "Epoch 437/500\n",
      "580/580 [==============================] - 0s 332us/sample - loss: 1.1717 - mean_absolute_error: 0.8548 - mean_squared_error: 1.1717\n",
      "Epoch 438/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.0921 - mean_absolute_error: 0.8371 - mean_squared_error: 1.0921\n",
      "Epoch 439/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.2315 - mean_absolute_error: 0.8960 - mean_squared_error: 1.2315\n",
      "Epoch 440/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.1142 - mean_absolute_error: 0.8531 - mean_squared_error: 1.1142\n",
      "Epoch 441/500\n",
      "580/580 [==============================] - 0s 334us/sample - loss: 1.1984 - mean_absolute_error: 0.8820 - mean_squared_error: 1.1984\n",
      "Epoch 442/500\n",
      "580/580 [==============================] - 0s 70us/sample - loss: 1.1341 - mean_absolute_error: 0.8529 - mean_squared_error: 1.1341\n",
      "Epoch 443/500\n",
      "580/580 [==============================] - 0s 122us/sample - loss: 1.2216 - mean_absolute_error: 0.8957 - mean_squared_error: 1.2216\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 0s 194us/sample - loss: 1.1648 - mean_absolute_error: 0.8648 - mean_squared_error: 1.1648\n",
      "Epoch 445/500\n",
      "580/580 [==============================] - 0s 191us/sample - loss: 1.1452 - mean_absolute_error: 0.8662 - mean_squared_error: 1.1452\n",
      "Epoch 446/500\n",
      "580/580 [==============================] - 0s 77us/sample - loss: 1.0888 - mean_absolute_error: 0.8405 - mean_squared_error: 1.0888\n",
      "Epoch 447/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.1740 - mean_absolute_error: 0.8767 - mean_squared_error: 1.1740\n",
      "Epoch 448/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.0449 - mean_absolute_error: 0.8095 - mean_squared_error: 1.0449\n",
      "Epoch 449/500\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 1.1785 - mean_absolute_error: 0.8733 - mean_squared_error: 1.1785\n",
      "Epoch 450/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.1799 - mean_absolute_error: 0.8808 - mean_squared_error: 1.1799\n",
      "Epoch 451/500\n",
      "580/580 [==============================] - 0s 107us/sample - loss: 1.2020 - mean_absolute_error: 0.8882 - mean_squared_error: 1.2020\n",
      "Epoch 452/500\n",
      "580/580 [==============================] - 0s 108us/sample - loss: 1.1633 - mean_absolute_error: 0.8668 - mean_squared_error: 1.1633\n",
      "Epoch 453/500\n",
      "580/580 [==============================] - 0s 349us/sample - loss: 1.1929 - mean_absolute_error: 0.8725 - mean_squared_error: 1.1929\n",
      "Epoch 454/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.1359 - mean_absolute_error: 0.8446 - mean_squared_error: 1.1359\n",
      "Epoch 455/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.0916 - mean_absolute_error: 0.8411 - mean_squared_error: 1.0916\n",
      "Epoch 456/500\n",
      "580/580 [==============================] - 0s 101us/sample - loss: 1.0827 - mean_absolute_error: 0.8314 - mean_squared_error: 1.0827\n",
      "Epoch 457/500\n",
      "580/580 [==============================] - 0s 347us/sample - loss: 1.1624 - mean_absolute_error: 0.8528 - mean_squared_error: 1.1624\n",
      "Epoch 458/500\n",
      "580/580 [==============================] - 0s 296us/sample - loss: 1.1605 - mean_absolute_error: 0.8621 - mean_squared_error: 1.1605\n",
      "Epoch 459/500\n",
      "580/580 [==============================] - 0s 117us/sample - loss: 1.1447 - mean_absolute_error: 0.8588 - mean_squared_error: 1.1447\n",
      "Epoch 460/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.0929 - mean_absolute_error: 0.8428 - mean_squared_error: 1.0929\n",
      "Epoch 461/500\n",
      "580/580 [==============================] - 0s 323us/sample - loss: 1.0738 - mean_absolute_error: 0.8409 - mean_squared_error: 1.0738\n",
      "Epoch 462/500\n",
      "580/580 [==============================] - 0s 103us/sample - loss: 1.1510 - mean_absolute_error: 0.8807 - mean_squared_error: 1.1510\n",
      "Epoch 463/500\n",
      "580/580 [==============================] - 0s 143us/sample - loss: 1.1592 - mean_absolute_error: 0.8646 - mean_squared_error: 1.1592\n",
      "Epoch 464/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.1274 - mean_absolute_error: 0.8575 - mean_squared_error: 1.1274\n",
      "Epoch 465/500\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 1.1041 - mean_absolute_error: 0.8501 - mean_squared_error: 1.1041\n",
      "Epoch 466/500\n",
      "580/580 [==============================] - 0s 120us/sample - loss: 1.1412 - mean_absolute_error: 0.8586 - mean_squared_error: 1.1412\n",
      "Epoch 467/500\n",
      "580/580 [==============================] - 0s 100us/sample - loss: 1.1268 - mean_absolute_error: 0.8564 - mean_squared_error: 1.1268\n",
      "Epoch 468/500\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 1.1554 - mean_absolute_error: 0.8589 - mean_squared_error: 1.1554\n",
      "Epoch 469/500\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 1.1139 - mean_absolute_error: 0.8577 - mean_squared_error: 1.1139\n",
      "Epoch 470/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.0832 - mean_absolute_error: 0.8292 - mean_squared_error: 1.0832\n",
      "Epoch 471/500\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 1.2361 - mean_absolute_error: 0.8854 - mean_squared_error: 1.2361\n",
      "Epoch 472/500\n",
      "580/580 [==============================] - 0s 373us/sample - loss: 1.1838 - mean_absolute_error: 0.8822 - mean_squared_error: 1.1838\n",
      "Epoch 473/500\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 1.1407 - mean_absolute_error: 0.8470 - mean_squared_error: 1.1407\n",
      "Epoch 474/500\n",
      "580/580 [==============================] - 0s 110us/sample - loss: 1.2229 - mean_absolute_error: 0.8768 - mean_squared_error: 1.2229\n",
      "Epoch 475/500\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 1.0808 - mean_absolute_error: 0.8305 - mean_squared_error: 1.0808\n",
      "Epoch 476/500\n",
      "580/580 [==============================] - 0s 310us/sample - loss: 1.1538 - mean_absolute_error: 0.8635 - mean_squared_error: 1.1538\n",
      "Epoch 477/500\n",
      "580/580 [==============================] - 0s 122us/sample - loss: 1.1003 - mean_absolute_error: 0.8505 - mean_squared_error: 1.1003\n",
      "Epoch 478/500\n",
      "580/580 [==============================] - 0s 163us/sample - loss: 1.0934 - mean_absolute_error: 0.8405 - mean_squared_error: 1.0934\n",
      "Epoch 479/500\n",
      "580/580 [==============================] - 0s 155us/sample - loss: 1.1470 - mean_absolute_error: 0.8595 - mean_squared_error: 1.1470\n",
      "Epoch 480/500\n",
      "580/580 [==============================] - 0s 112us/sample - loss: 1.1186 - mean_absolute_error: 0.8469 - mean_squared_error: 1.1186\n",
      "Epoch 481/500\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 1.2094 - mean_absolute_error: 0.8865 - mean_squared_error: 1.2094\n",
      "Epoch 482/500\n",
      "580/580 [==============================] - 0s 310us/sample - loss: 1.1250 - mean_absolute_error: 0.8517 - mean_squared_error: 1.1250\n",
      "Epoch 483/500\n",
      "580/580 [==============================] - 0s 122us/sample - loss: 1.1556 - mean_absolute_error: 0.8671 - mean_squared_error: 1.1556\n",
      "Epoch 484/500\n",
      "580/580 [==============================] - 0s 96us/sample - loss: 1.0707 - mean_absolute_error: 0.8418 - mean_squared_error: 1.0707\n",
      "Epoch 485/500\n",
      "580/580 [==============================] - 0s 67us/sample - loss: 1.1814 - mean_absolute_error: 0.8764 - mean_squared_error: 1.1814\n",
      "Epoch 486/500\n",
      "580/580 [==============================] - 0s 365us/sample - loss: 1.1638 - mean_absolute_error: 0.8651 - mean_squared_error: 1.1638\n",
      "Epoch 487/500\n",
      "580/580 [==============================] - 0s 162us/sample - loss: 1.1321 - mean_absolute_error: 0.8455 - mean_squared_error: 1.1321\n",
      "Epoch 488/500\n",
      "580/580 [==============================] - 0s 96us/sample - loss: 1.1743 - mean_absolute_error: 0.8747 - mean_squared_error: 1.1743\n",
      "Epoch 489/500\n",
      "580/580 [==============================] - 0s 96us/sample - loss: 1.0215 - mean_absolute_error: 0.8155 - mean_squared_error: 1.0215\n",
      "Epoch 490/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.0837 - mean_absolute_error: 0.8347 - mean_squared_error: 1.0837\n",
      "Epoch 491/500\n",
      "580/580 [==============================] - 0s 155us/sample - loss: 1.1652 - mean_absolute_error: 0.8489 - mean_squared_error: 1.1652\n",
      "Epoch 492/500\n",
      "580/580 [==============================] - 0s 306us/sample - loss: 1.2062 - mean_absolute_error: 0.8879 - mean_squared_error: 1.2062\n",
      "Epoch 493/500\n",
      "580/580 [==============================] - 0s 158us/sample - loss: 1.1006 - mean_absolute_error: 0.8467 - mean_squared_error: 1.1006\n",
      "Epoch 494/500\n",
      "580/580 [==============================] - 0s 144us/sample - loss: 1.0551 - mean_absolute_error: 0.8270 - mean_squared_error: 1.0551\n",
      "Epoch 495/500\n",
      "580/580 [==============================] - 0s 256us/sample - loss: 1.1292 - mean_absolute_error: 0.8523 - mean_squared_error: 1.1292\n",
      "Epoch 496/500\n",
      "580/580 [==============================] - 0s 191us/sample - loss: 1.0535 - mean_absolute_error: 0.8241 - mean_squared_error: 1.0535\n",
      "Epoch 497/500\n",
      "580/580 [==============================] - 0s 129us/sample - loss: 1.1984 - mean_absolute_error: 0.8891 - mean_squared_error: 1.1984\n",
      "Epoch 498/500\n",
      "580/580 [==============================] - 0s 162us/sample - loss: 1.0700 - mean_absolute_error: 0.8379 - mean_squared_error: 1.0700\n",
      "Epoch 499/500\n",
      "580/580 [==============================] - 0s 141us/sample - loss: 1.1759 - mean_absolute_error: 0.8714 - mean_squared_error: 1.1759\n",
      "Epoch 500/500\n",
      "580/580 [==============================] - 0s 105us/sample - loss: 1.1226 - mean_absolute_error: 0.8601 - mean_squared_error: 1.1226\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation = tf.nn.relu, input_dim = 5), ##dimension = no. of independent variables\n",
    "        tf.keras.layers.Dense(64, activation = tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1) ## don't use any function as it is regression problem and target variable is numeric\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)  ## define learning rate\n",
    "    \n",
    "    model.compile(loss= 'mse',\n",
    "                 optimizer = optimizer,\n",
    "                 metrics = ['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "neural = model.fit(lcn_x_train, lcn_y_train, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 500,\n",
       " 'steps': None,\n",
       " 'samples': 580,\n",
       " 'verbose': 1,\n",
       " 'do_validation': False,\n",
       " 'metrics': ['loss', 'mean_absolute_error', 'mean_squared_error']}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1= model.predict(lcn_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4774036],\n",
       "       [ 5.7576857],\n",
       "       [ 6.4745274],\n",
       "       [10.76802  ],\n",
       "       [ 3.4609327],\n",
       "       [ 5.7205143],\n",
       "       [ 7.592081 ],\n",
       "       [ 4.9705253],\n",
       "       [ 8.877076 ],\n",
       "       [ 5.3582234],\n",
       "       [11.750628 ],\n",
       "       [ 7.6548376],\n",
       "       [ 6.177159 ],\n",
       "       [10.5900955],\n",
       "       [ 4.3813524],\n",
       "       [ 7.8881807],\n",
       "       [ 5.319628 ],\n",
       "       [ 7.9295254],\n",
       "       [ 4.762062 ],\n",
       "       [ 7.8051653],\n",
       "       [10.740243 ],\n",
       "       [ 7.819565 ],\n",
       "       [ 8.9759245],\n",
       "       [ 8.55827  ],\n",
       "       [ 8.404922 ],\n",
       "       [ 6.392653 ],\n",
       "       [10.227523 ],\n",
       "       [ 9.598737 ],\n",
       "       [ 8.167082 ],\n",
       "       [11.227326 ],\n",
       "       [ 8.421481 ],\n",
       "       [ 6.7828217],\n",
       "       [ 9.844886 ],\n",
       "       [ 5.2779655],\n",
       "       [11.163188 ],\n",
       "       [ 9.326644 ],\n",
       "       [ 3.5191097],\n",
       "       [ 8.8711405],\n",
       "       [ 4.576206 ],\n",
       "       [ 7.7225075],\n",
       "       [ 5.9401026],\n",
       "       [ 8.860074 ],\n",
       "       [ 7.7122145],\n",
       "       [ 9.181266 ],\n",
       "       [ 7.5091057],\n",
       "       [ 6.0808973],\n",
       "       [ 7.2539167],\n",
       "       [ 8.185483 ],\n",
       "       [ 8.447192 ],\n",
       "       [ 6.634947 ],\n",
       "       [ 4.735482 ],\n",
       "       [ 8.429675 ],\n",
       "       [ 7.025068 ],\n",
       "       [ 6.1054544],\n",
       "       [10.189634 ],\n",
       "       [10.22947  ],\n",
       "       [12.802993 ],\n",
       "       [ 4.1224914],\n",
       "       [ 0.8618877],\n",
       "       [ 3.3389702],\n",
       "       [10.553119 ],\n",
       "       [10.923849 ],\n",
       "       [10.726615 ],\n",
       "       [ 5.0940742],\n",
       "       [ 6.836794 ],\n",
       "       [ 7.8011923],\n",
       "       [10.859322 ],\n",
       "       [ 2.2101793],\n",
       "       [ 4.6133766],\n",
       "       [ 9.573598 ],\n",
       "       [10.087567 ],\n",
       "       [10.637586 ],\n",
       "       [10.008755 ],\n",
       "       [ 7.0911913],\n",
       "       [ 9.885133 ],\n",
       "       [ 9.154307 ],\n",
       "       [ 7.4331675],\n",
       "       [ 8.388793 ],\n",
       "       [ 8.3555   ],\n",
       "       [ 3.4466639],\n",
       "       [ 5.887786 ],\n",
       "       [ 9.225628 ],\n",
       "       [ 9.713658 ],\n",
       "       [ 4.2704186],\n",
       "       [10.924301 ],\n",
       "       [ 7.6389656],\n",
       "       [ 4.929332 ],\n",
       "       [ 7.677909 ],\n",
       "       [ 7.685589 ],\n",
       "       [ 8.264569 ],\n",
       "       [10.655187 ],\n",
       "       [ 8.116523 ],\n",
       "       [ 4.576206 ],\n",
       "       [10.538087 ],\n",
       "       [ 9.916669 ],\n",
       "       [ 4.8735743],\n",
       "       [ 8.812335 ],\n",
       "       [ 7.964411 ],\n",
       "       [ 8.482039 ],\n",
       "       [11.451301 ],\n",
       "       [ 3.7092319],\n",
       "       [ 7.5326786],\n",
       "       [12.015665 ],\n",
       "       [ 7.437049 ],\n",
       "       [ 8.152656 ],\n",
       "       [ 8.156077 ],\n",
       "       [ 5.2984233],\n",
       "       [ 5.426203 ],\n",
       "       [ 7.455778 ],\n",
       "       [ 6.811643 ],\n",
       "       [10.263507 ],\n",
       "       [ 2.447988 ],\n",
       "       [ 9.53818  ],\n",
       "       [ 8.213618 ],\n",
       "       [11.131717 ],\n",
       "       [ 9.671582 ],\n",
       "       [10.810513 ],\n",
       "       [ 8.1942   ],\n",
       "       [ 9.641475 ],\n",
       "       [10.291324 ],\n",
       "       [ 6.4647055],\n",
       "       [10.104579 ],\n",
       "       [ 2.152843 ],\n",
       "       [ 8.089129 ],\n",
       "       [10.757254 ],\n",
       "       [ 8.859296 ],\n",
       "       [11.188944 ],\n",
       "       [10.542813 ],\n",
       "       [10.491856 ],\n",
       "       [ 7.9537   ],\n",
       "       [ 3.3682652],\n",
       "       [ 5.50576  ],\n",
       "       [10.100502 ],\n",
       "       [ 7.3440294],\n",
       "       [ 9.708796 ],\n",
       "       [ 8.200292 ],\n",
       "       [ 8.473214 ],\n",
       "       [10.421172 ],\n",
       "       [ 9.725807 ],\n",
       "       [ 8.644355 ],\n",
       "       [ 9.880374 ],\n",
       "       [ 9.310605 ],\n",
       "       [ 6.8257666],\n",
       "       [ 5.8797903],\n",
       "       [ 8.398444 ]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.93042725e-01, -2.77521789e-01, -1.54277518e-01,\n",
       "         -1.38814524e-01, -3.23823839e-01, -3.25451553e-01,\n",
       "         -6.21897019e-02, -4.84723300e-02, -2.64915019e-01,\n",
       "         -1.62420169e-01,  8.26725364e-03, -2.70037353e-01,\n",
       "          4.90220671e-04,  4.17458415e-02, -1.42578274e-01,\n",
       "          1.95862710e-01, -2.25227177e-01,  3.87789565e-03,\n",
       "         -5.04295714e-02, -1.01915203e-01, -2.00302064e-01,\n",
       "         -2.49939799e-01, -2.20162421e-01, -2.36742105e-02,\n",
       "         -2.21919149e-01, -2.40602523e-01, -2.13572979e-02,\n",
       "         -3.41899991e-02, -1.00689670e-02, -2.47425035e-01,\n",
       "         -3.97627175e-01,  2.23227501e-01,  2.00205415e-01,\n",
       "          6.86279535e-02,  1.66890509e-02, -2.11338252e-01,\n",
       "          1.34783119e-01,  2.04807818e-01,  1.47371054e-01,\n",
       "          2.25522488e-01,  2.24295199e-01,  7.31882006e-02,\n",
       "         -2.82129705e-01, -2.12998807e-01,  1.40213460e-01,\n",
       "         -1.32736653e-01,  5.08908294e-02, -8.70006606e-02,\n",
       "         -2.45785251e-01,  1.54336423e-01,  1.53586835e-01,\n",
       "         -4.13641483e-01, -1.84990942e-01,  3.28269303e-02,\n",
       "          1.95507348e-01, -1.01431027e-01, -2.15641260e-01,\n",
       "         -1.60645097e-01,  8.88706222e-02,  2.54046649e-01,\n",
       "         -1.50222689e-01,  1.51000515e-01, -4.93756264e-01,\n",
       "          8.96154940e-02],\n",
       "        [-1.07754678e-01,  5.24752028e-02,  2.32407339e-02,\n",
       "         -2.51347125e-01,  2.42513064e-02,  1.48136348e-01,\n",
       "          1.31978586e-01, -2.71837384e-01,  5.13893776e-02,\n",
       "          1.51925394e-02, -9.33029056e-02, -2.26134896e-01,\n",
       "          1.38648957e-01, -2.45450988e-01, -1.43264025e-01,\n",
       "          1.52138889e-01, -2.35875607e-01,  6.54966745e-04,\n",
       "          1.54905230e-01,  4.85367887e-03, -1.74714833e-01,\n",
       "         -9.66921449e-03,  1.11461446e-01,  1.76223591e-01,\n",
       "         -1.37326121e-02,  4.35786098e-02, -6.88265711e-02,\n",
       "         -1.78085268e-02,  1.95255829e-03, -1.03609234e-01,\n",
       "          1.29782036e-02, -1.34881027e-02, -2.17553228e-01,\n",
       "         -2.74274945e-01,  2.10738671e-03, -1.68938369e-01,\n",
       "          1.57930598e-01, -1.83026612e-01,  6.46841573e-03,\n",
       "         -3.48484591e-02, -1.38704136e-01, -8.28358810e-03,\n",
       "          3.95681523e-02, -1.86565235e-01, -1.41456187e-01,\n",
       "          1.38385063e-02,  1.12156741e-01,  1.25084049e-03,\n",
       "          5.10812588e-02, -1.66623071e-01, -1.49286002e-01,\n",
       "          3.17539461e-02, -2.50981718e-01, -8.84139352e-03,\n",
       "          5.76648004e-02, -1.96416482e-01, -2.22719282e-01,\n",
       "          1.15905493e-01,  1.60266664e-02, -7.11943060e-02,\n",
       "         -9.67419744e-02,  1.33243635e-01,  3.18612866e-02,\n",
       "         -1.30282551e-01],\n",
       "        [-1.22399628e-02,  2.01429781e-02,  4.44774151e-01,\n",
       "         -2.21631527e-01,  9.47751030e-02, -2.50110161e-02,\n",
       "         -5.03382646e-02, -1.30844086e-01,  2.70659655e-01,\n",
       "         -3.61584097e-01,  1.58223212e-01,  1.42047107e-01,\n",
       "         -2.76103914e-01,  1.14332497e-01,  8.35121870e-02,\n",
       "          5.09249512e-03,  2.58164287e-01, -3.97809029e-01,\n",
       "         -4.02980059e-01, -2.25277424e-01, -2.40514874e-02,\n",
       "          3.20112109e-02, -4.29518551e-01, -2.78209180e-01,\n",
       "          1.77011311e-01, -5.24832048e-02, -1.18368745e-01,\n",
       "          2.37786829e-01, -1.28554061e-01,  1.85114056e-01,\n",
       "         -3.43479030e-02, -1.94914341e-01,  2.13885307e-03,\n",
       "          2.32221186e-01,  1.42857641e-01, -8.48709792e-02,\n",
       "         -6.66433498e-02,  1.13843441e-01, -3.23580265e-01,\n",
       "         -5.22408523e-02, -2.79386044e-02, -1.11620314e-02,\n",
       "         -7.36745477e-01,  7.12921321e-02, -2.52979994e-02,\n",
       "          1.31385298e-02,  6.64653704e-02,  4.89734001e-02,\n",
       "         -1.59427956e-01, -2.28019863e-01, -2.68267989e-02,\n",
       "          2.80632704e-01, -6.98840320e-02, -1.64044708e-01,\n",
       "         -2.95193970e-01, -2.49263644e-02, -2.33343542e-02,\n",
       "         -3.47936116e-02,  1.87978372e-01,  1.10260889e-01,\n",
       "          1.77895546e-01, -3.24667126e-01,  1.94731653e-01,\n",
       "          2.51756608e-02],\n",
       "        [ 1.79138482e-02,  3.46012086e-01, -1.04837477e+00,\n",
       "         -2.70508528e-02, -7.67511547e-01, -3.16949457e-01,\n",
       "         -1.45920321e-01, -1.07226267e-01, -1.32672796e-02,\n",
       "         -8.44867975e-02,  2.77840614e-01, -2.35572174e-01,\n",
       "         -1.16719753e-01, -2.79348493e-01,  1.01090252e-01,\n",
       "          1.45082891e-01, -1.79607421e-01,  1.06685169e-01,\n",
       "         -2.66554326e-01, -1.90770760e-01, -2.03363270e-01,\n",
       "          2.39833713e-01,  1.72708288e-01, -4.10524547e-01,\n",
       "         -1.56503245e-01,  1.44644439e-01,  2.68146992e-02,\n",
       "          2.93853462e-01, -1.34911090e-01, -1.21575177e-01,\n",
       "         -7.89827168e-01, -1.53818488e-01, -1.24300301e-01,\n",
       "         -2.69523412e-01, -1.30287826e+00,  2.29103684e-01,\n",
       "          8.90149921e-02,  1.14217401e-02, -1.84612125e-02,\n",
       "          1.05259269e-01,  1.71049654e-01, -1.33998954e+00,\n",
       "         -2.13894285e-02,  1.98353827e-01, -2.75349021e-01,\n",
       "         -3.10531706e-01,  3.73480166e-03,  1.76409692e-01,\n",
       "          5.12836948e-02,  1.39438063e-01,  7.04365075e-02,\n",
       "         -9.67624664e-01, -1.68422893e-01,  1.09758610e-02,\n",
       "         -2.85779148e-01,  1.65693164e-02,  1.02873981e-01,\n",
       "         -9.81606916e-02, -1.30481437e-01,  5.36865629e-02,\n",
       "          4.90134060e-02, -3.46041530e-01, -7.00560331e-01,\n",
       "         -2.00467080e-01],\n",
       "        [ 1.52651042e-01,  3.82520616e-01, -1.78846136e-01,\n",
       "         -7.63961077e-02,  4.23379928e-01,  1.38491929e-01,\n",
       "         -7.15663582e-02, -1.36285052e-01,  2.96510816e-01,\n",
       "         -3.58810753e-01, -6.85622245e-02, -9.41172540e-02,\n",
       "         -1.63461432e-01, -6.47847503e-02,  1.57340169e-01,\n",
       "         -9.35781151e-02, -7.68017769e-02, -2.75681823e-01,\n",
       "         -2.68230766e-01, -1.88268110e-01, -4.19045687e-02,\n",
       "          1.21423602e-02, -7.84128681e-02,  4.54388186e-02,\n",
       "          6.36446774e-02,  3.20366532e-01,  1.81446761e-01,\n",
       "          9.50402319e-02,  3.69564863e-03, -2.85398036e-01,\n",
       "          3.84659052e-01,  2.48344600e-01,  2.87955880e-01,\n",
       "         -2.01318488e-01,  1.02416530e-01, -3.69587839e-02,\n",
       "         -1.85025990e-01,  2.16102660e-01, -3.31100752e-03,\n",
       "          1.70919243e-02,  1.40180141e-01, -1.64401233e-02,\n",
       "         -9.98601675e-01, -2.89548695e-01, -1.25129774e-01,\n",
       "         -3.84054661e-01, -1.40739575e-01,  7.96123371e-02,\n",
       "         -7.46293515e-02,  4.08177972e-02,  2.89456606e-01,\n",
       "          5.19028842e-01, -1.20825797e-01, -3.08833808e-01,\n",
       "          9.03118104e-02,  2.90111184e-01, -1.40894100e-01,\n",
       "         -2.25079700e-01, -2.92203724e-01,  2.45863214e-01,\n",
       "         -2.22981885e-01,  6.95797727e-02,  2.36545935e-01,\n",
       "          1.35560840e-01]], dtype=float32),\n",
       " array([ 0.        ,  0.85174435,  0.428987  ,  0.        ,  0.01389658,\n",
       "        -0.94745123, -0.9664739 ,  0.        ,  0.83322775, -0.33615583,\n",
       "         0.        ,  0.        , -0.91912484,  0.        ,  0.        ,\n",
       "        -0.8585827 ,  0.        , -0.24379249, -0.8937543 ,  0.01844372,\n",
       "         0.        ,  0.        , -0.9468754 , -0.9385621 ,  0.        ,\n",
       "         0.78212595,  0.        ,  0.        , -0.07523582,  0.        ,\n",
       "         0.12569785, -0.7776347 ,  0.        ,  0.        ,  0.64188486,\n",
       "         0.        ,  0.7351116 ,  0.        , -0.9556052 , -0.7183082 ,\n",
       "         0.        ,  0.52151257,  0.6796874 ,  0.        ,  0.        ,\n",
       "         0.69858885,  0.70182496, -0.06463115,  0.86216563,  0.        ,\n",
       "         0.        , -0.0639029 ,  0.        , -0.11835568, -0.87713605,\n",
       "         0.        ,  0.        , -0.90556175,  0.7142154 ,  0.04330157,\n",
       "         0.        , -0.9344756 ,  0.2539798 ,  0.        ], dtype=float32),\n",
       " array([[ 0.06529646,  0.03657444,  0.08391924, ...,  0.02128965,\n",
       "         -0.12637815, -0.07795744],\n",
       "        [-0.25213915,  0.03304693, -0.03740085, ...,  0.05442525,\n",
       "         -0.07089372,  0.17384438],\n",
       "        [-0.35314497,  0.19521935, -0.04076637, ..., -0.07048933,\n",
       "          0.18814524, -0.05007748],\n",
       "        ...,\n",
       "        [-0.11827224,  0.04733078, -0.09413144, ..., -0.20226504,\n",
       "         -0.08830082,  0.04003151],\n",
       "        [-0.08431649, -0.03456123,  0.10645112, ...,  0.1132897 ,\n",
       "         -0.1629916 ,  0.09042068],\n",
       "        [-0.14233208, -0.18167144,  0.09708144, ..., -0.15870628,\n",
       "          0.09269176,  0.08111529]], dtype=float32),\n",
       " array([-0.82219774,  0.        , -0.13105948, -0.00958588, -0.00858607,\n",
       "         0.        , -0.81669766,  0.01622189, -0.02936244,  0.27424538,\n",
       "         0.84100115,  0.21241564, -0.00528454, -0.84833235,  0.        ,\n",
       "         0.        , -0.817414  , -0.10918109,  0.59243524,  0.        ,\n",
       "         0.0778911 ,  0.06197585,  0.10210422, -0.28509057,  0.        ,\n",
       "        -0.8268051 ,  0.7952733 ,  0.        ,  0.0121429 ,  0.        ,\n",
       "         0.7910805 , -0.8446516 , -0.81931156,  0.        , -0.18562411,\n",
       "        -0.83939713,  0.0322672 ,  0.027162  , -0.81729347, -0.59714586,\n",
       "         0.        , -0.01875406,  0.        ,  0.        , -0.00632357,\n",
       "        -0.00316216,  0.43551138, -0.04110798, -0.00339763,  0.00298832,\n",
       "        -0.01264675,  0.        ,  0.81376094,  0.12544642, -0.6595712 ,\n",
       "         0.        ,  0.        ,  0.        , -0.00948673,  0.06041189,\n",
       "        -0.824894  ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
       " array([[ 0.24026752],\n",
       "        [ 0.05019361],\n",
       "        [ 0.04876203],\n",
       "        [ 0.04645595],\n",
       "        [-0.02356794],\n",
       "        [-0.09497206],\n",
       "        [ 0.31006718],\n",
       "        [ 0.00109974],\n",
       "        [ 0.001633  ],\n",
       "        [-0.13683726],\n",
       "        [-0.15006982],\n",
       "        [-0.29411972],\n",
       "        [-0.24125198],\n",
       "        [ 0.12199824],\n",
       "        [ 0.1310255 ],\n",
       "        [ 0.17593896],\n",
       "        [ 0.2922734 ],\n",
       "        [ 0.00255296],\n",
       "        [-0.19576737],\n",
       "        [ 0.26304996],\n",
       "        [-0.03312644],\n",
       "        [-0.16357848],\n",
       "        [-0.19027297],\n",
       "        [ 0.00254468],\n",
       "        [ 0.14402905],\n",
       "        [ 0.16909626],\n",
       "        [-0.2075636 ],\n",
       "        [ 0.05004939],\n",
       "        [-0.1148264 ],\n",
       "        [-0.18627948],\n",
       "        [-0.38391468],\n",
       "        [ 0.11061756],\n",
       "        [ 0.27092206],\n",
       "        [ 0.0796771 ],\n",
       "        [ 0.07872273],\n",
       "        [ 0.18446286],\n",
       "        [-0.00433219],\n",
       "        [-0.02352376],\n",
       "        [ 0.30064023],\n",
       "        [ 0.0213009 ],\n",
       "        [ 0.28782982],\n",
       "        [-0.0952474 ],\n",
       "        [-0.25955367],\n",
       "        [-0.00864628],\n",
       "        [ 0.07527272],\n",
       "        [ 0.2983628 ],\n",
       "        [-0.01713588],\n",
       "        [ 0.16986121],\n",
       "        [ 0.17859527],\n",
       "        [-0.28554514],\n",
       "        [-0.21754506],\n",
       "        [ 0.27375966],\n",
       "        [-0.18992531],\n",
       "        [-0.00040403],\n",
       "        [ 0.10280357],\n",
       "        [-0.23416726],\n",
       "        [-0.15770708],\n",
       "        [ 0.0075739 ],\n",
       "        [ 0.19460715],\n",
       "        [-0.01489205],\n",
       "        [ 0.20172952],\n",
       "        [ 0.0381723 ],\n",
       "        [-0.20406494],\n",
       "        [-0.11495519]], dtype=float32),\n",
       " array([-0.8045646], dtype=float32)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,609\n",
      "Trainable params: 4,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
